%%VOG*

Une première technique de compression usant de ces méthodes s'intitule 
\newacronym{vog}{VOG}{Vocabulary Graph}
\gls{vog}
 \citep{koutra2015summarizing}. C'est une méthode de base sur laquelle s'appuient toutes les autres méthodes de cette classe. Elle permet de compresser un graphe statique non orienté G à l'aide d'un vocabulaire de sous-structures qui apparaissent fréquemment dans les graphes réels et ayant  une signification sémantique, tout en minimisant le cout du codage en utilisant le principe de longueur de description minimale (\gls{mdl})\footnote{MDL est un concept de la théorie de l'information permettant de trouver le modèle ayant une longueur minimale: \textit{min}(\textit{D},\textit{M}) = L(\textit{M}) + L(\textit{D} | \textit{M}) où L(\textit{M}) est la longueur du modèle et L(\textit{D} | \textit{M}) est la longueur en bits de la description des donnés en utilisant le modèle \textit{M}.}. 
%Soit un graphe non orienté G(V,E), sans boucle avec n nœuds et m arêtes et soit A sa matrice d'adjacence. le résultat de \gls{vog} est une liste ordonnée de structures notés \textit{M}, on note par 
Le vocabulaire $\Omega$ utilisé est composé de six structures qui sont : clique (\textit{fc}) et quasi-clique (\textit{nc}), noyau bipartie (\textit{cb}) et quasi-noyau bipartie (\textit{nb}), étoile (\textit{st}) et chaine (\textit{ch}). On peut avoir un chevauchement au niveau des nœuds, les liens quand à eux sont pris selon un ordre FIFO et ne peuvent pas se chevaucher, i.e, la première structure $ s \in \textit{M} $ qui décrit l'arête dans A détermine sa valeur.

On note par $\mathcal{C}_{x}$ l'ensemble de tous les sous-graphes possibles de type $x \in \Omega$, et $\mathcal{C}$ l'union de tous ces ensembles, $\mathcal{C}$ = ${\cup}_{x}\mathcal{C}_{x}$. La famille de modèles noté $\mathcal{M}$ représente toutes les permutations possibles des éléments de $\mathcal{C}$. Par MDL, on cherche $\textit{M} \in \mathcal{M}$ qui minimise le mieux le cout de stockage du modèle et de la matrice d'adjacence.
En d'autre terme, \gls{vog} formule le problème de compression comme un problème d'optimisation dont la fonction objective est :
 
 
 \textit{min}(\textit{D},\textit{M}) = L(\textit{M}) + L(E) avec E= A $\bigoplus$ $\mathbf{M} $ représentant l'erreur. 

Pour l'encodage du modèle, on a pour chaque $\textit{M} \in  \mathcal{M}$ : 

\begin{center}
L(\textit{M}) = $L_{\mathbb{N}}$(|M|+1) + log $\left( \begin{array}{c}
|\textit{M}| + |\Omega| -1 \\
|\Omega| -1 \\
\end{array} \right)$ + $\sum\limits_{s  \in \textit{M}} ( - log Pr(x(s)  |  \textit{M} ) + L(s) )$\\
\end{center}

Le premier terme représente le nombre de structures dans le modèle  %$L_{\mathbb{N}}$
, le second terme encode le nombre de structures par type $x \in \Omega$ tant dis que le troisième terme permet pour chaque structure $s \in \textit{M}$, d'encoder son type x(s) avec un code de préfixe optimal et d'encoder sa structure. Le codage des structures se fait selon leurs types :
%----------------------------------------------------------------
%----------------------------------------------------------------
%----------------------------------------------------------------

\textbf{Clique :} Pour l'encodage d'une clique, on calcule le nombre de nœuds de celle-ci, et on encode leurs ids :
L(\textit{fc}) = $L_{\mathbb{N}}$(|\textit{fc}|) + log ${n}\choose{|f_{c}|}$
%----------------------------------------------------------------
%----------------------------------------------------------------
%----------------------------------------------------------------

\textbf{Quasi-Clique :} Les quasi-cliques sont encodées comme des cliques complètes, tout en identifiant les arêtes ajoutées dont le nombre est ||\textit{nc}|| et manquantes dont le nombre est noté ||\textit{nc}||' en utilisant des codes de préfixe optimaux : 
L(\textit{nc}) = $L_{\mathbb{N}}$(|\textit{nc}|) + log ${n}\choose{|n_{c}|}$ + log(|\textit{nc})|) + ||\textit{nc}||\textit{$l_{1}$} +  ||\textit{nc}||'\textit{$l_{0}$}
où \textit{$l_{1}$} = - log(||\textit{nc}||/(||\textit{nc}||+||\textit{nc}||')) et analogique à \textit{$l_{0}$} sont les longueurs des codes de préfixe optimaux des arêtes  ajoutées et manquantes.
%----------------------------------------------------------------
%----------------------------------------------------------------
%----------------------------------------------------------------

\textbf{Noyau biparti :} notant par A et B les deux ensembles du noyau bipartie. On encode leurs tailles, ainsi que les identifiants de leurs sommets : 
L(\textit{fb}) = $L_{\mathbb{N}}$(|\textit{A}|) + $L_{\mathbb{N}}$(|\textit{B}|) + log ${n}\choose{|A|}$ + log ${n-|A|}\choose{|B|}$.
%----------------------------------------------------------------
%----------------------------------------------------------------
%----------------------------------------------------------------

\textbf{Quasi-Noyau biparti :} Comme les quasi-cliques, les quasi-noyaux bipartie sont codés comme suit :
L(\textit{nb}) = $L_{\mathbb{N}}$(|\textit{A}|) + $L_{\mathbb{N}}$(|\textit{B}|) + log ${n}\choose{|A|}$  + log ${n-|A|}\choose{|B|}$+log(|area(\textit{nb})|) + ||\textit{nb}||\textit{$l_{1}$} + ||\textit{nb}||'\textit{$l_{0}$}.
%----------------------------------------------------------------
%----------------------------------------------------------------
%----------------------------------------------------------------

\textbf{Étoile :} L'étoile est un cas particulier d'un noyau bipartie. D'abord on calcule le nombre de nœuds des extrémités de l'étoile, ensuite on identifie le nœud central parmi les n sommets et les nœuds des extrémités parmi les n-1 restants.
L(\textit{st}) = $L_{\mathbb{N}}$(|\textit{st}|-1) +  log n + log ${n-1}\choose{|st|-1}$.
%----------------------------------------------------------------
%----------------------------------------------------------------
%----------------------------------------------------------------

\textbf{Chaine :} On calcule d'abord le nombre d'éléments de la chaine, ensuite on encode les identifiants des nœuds selon leurs ordre dans la chaine :
L(\textit{ch}) = $L_{\mathbb{N}}$(|\textit{ch}| - 1) + $\sum\limits_{i=0}^{|\textit{ch}|} ( n - i )$

%----------------------------------------------------------------
%---------------------La matrice de l'erreur----------------------
%----------------------------------------------------------------
\textbf{Matrice d'erreur :} la matrice d'erreur E est encodée en deux parties $E^{+}$ et $E^{-}$. $E^{+}$  correspond à la partie de A que M modélise en rajoutant des liens non existants contrairement à $E^{-}$ qui représente les parties de A que M ne modélise pas. Notons que les quasi-cliques et les quasi-noyaux bipartie ne sont pas inclut dans la matrice d'erreur puisqu'ils sont encodés avec exactitude. Le codage de $E^{+}$ et $E^{-}$ est similaire à celui des quasi-cliques, on a :
\begin{center}
L(${E}^{+}$) = log(|${E}^{+}$|) + ||${E}^{+}$||\textit{$l_{1}$} + ||${E}^{+}$||'\textit{$l_{0}$}\\
L(${E}^{-}$) = log(|${E}^{-}$|) + ||${E}^{-}$||\textit{$l_{1}$} + ||${E}^{-}$||'\textit{$l_{0}$}\\
\end{center} 
Pour la recherche du meilleur modèle $ \textit{M} \in \mathcal{M} $ , \gls{vog} procède sur trois étapes :
%---------------------------------------------------
%---------------------etape 01----------------------
%---------------------------------------------------
\begin{enumerate}
 \item \textbf{Génération des sous-structures }: Dans cette phase, Les méthodes de détection de communautés et de clustering sont utilisées pour décomposer le graphe en sous-graphes pas forcément disjoints. La méthode de décomposition utilisée dans \gls{vog} est SlashBurn.  
%---------------------------------------------------
%---------------------etape 02----------------------
%---------------------------------------------------
 \item \textbf{Étiquetage des sous-graphes }: L'algorithme cherche pour chaque sous-graphe généré dans l'étape précédente la structure $x \in \Omega$ qui le décrit le mieux, en tolérant un certain seuil d'erreur.
  \begin{enumerate}[label=\alph*]
     \item \textbf{Étiquetage des structures parfaites} : Tout d'abord, le sous-graphe est testé pour une similarité sans erreur par rapport aux structures complètes du vocabulaire :
		%----------------------------------------------------
		%---------------------etape 2.1----------------------
		%----------------------------------------------------
\begin{itemize}[label=$\circ$]
	\item si tous les sommets d'un sous graphe d'ordre n ont un degré égale à n-1, il s'agit alors d'une clique.
	\item si tous les sommets ont un degré de 2 sauf deux sommets ayant le degré 1, le  sous-graphe est une chaine.
	\item si les amplitudes de ses valeurs propres maximales et minimales sont égales, le sous-graphe est un noyau bipartie où les sommet de chaque ensemble du noyau sont identifiés à travers un parcours 
	\newacronym{bfs}{BFS}{Breadth First Search}
	\gls{bfs}\footnote{\gls{bfs} : est un algorithme de parcours en largeur.}	
	 avec coloration des sommets.
	\item  Quant à l'étoile, elle est considérée comme un cas particulier d'un noyau bipartie, il suffit donc que l'un des ensembles soit composé d'un seule sommet.
\end{itemize}     
		%----------------------------------------------------
		%---------------------etape 2.2----------------------
		%----------------------------------------------------
     \item \textbf{Étiquetage des structures approximatives }: Si le sous graphe ne correspond pas à une structure complète, on cherche la structure qui l'approxime le mieux en terme du principe MDL.
     
  \end{enumerate} 
 % \textbf{Remarque} : Pour les structure parfaites, en plus du cout d'encodage de la structure, on rajoute le cout de l'erreur local c'est a dire, L($x^{*}$) + L($\textit{E}^{+}_{x^{*}}$) + L($\textit{E}^{-}_{x^{*}}$) où L($x^{*}$) est la description de la structure, L($\textit{E}^{+}_{x^{*}}$) et L($\textit{E}^{-}_{x^{*}}$) sont les arêtes incorrectement modélisés et les arêtes non  modélisés respectivement dans area($x^{*}$).
  
  
Après avoir représenté le sous graphe sous forme d'une structure, on l'ajoute à l'ensemble des structures candidates $\mathcal{C}$, en l'associant à son cout.

\item \textbf{Assemblage du modèle }: Dans cette dernière étape, une sélection d'un ensemble de structures parmi ceux de $\mathcal{C}$ est réalisée. Des heuristiques de sélections sont utilisées car le nombre de permutations est très grand ce qui implique des calculs exhaustifs. Les heuristiques permettent d'avoir des résultats approximatifs et rapides, parmi les heuristiques utilisées dans \gls{vog} on trouve :
\begin{itemize}
\item PLAIN : Cette heuristique retourne toutes les structures candidates, e.i, \textit{M}= $\mathcal{C}$.
\item TOP-K :  Cette heuristique sélectionne les k meilleurs candidats en fonction de leur gain en bits.
\item GREEDY'N FORGET(GNF) : Parcourt structure par structure dans l'ensemble $\mathcal{C}$ ordonné selon la qualité (gain en bits), ajoute la structure au modèle tant qu'elle n'augmente pas le cout total de la représentation, sinon l'ignore.
%matnsaych kayn réf ta3had la méthode w matnsaych aussi réf ta3 mdl
\end{itemize}  
\end{enumerate}

%Ci-dessous le pseudo algorithme de \gls{vog} :

%\begin{algorithm}
%\caption{Pseudo Algorithme VOG}\label{euclid}
%\begin{algorithmic}[1]
%	\STATE \textbf{Entré :} Graphe G.
%	\STATE \textbf{Étape 1 :}  Génération des sous-graphe en utilisant une méthode de décomposition.  
%	\STATE \textbf{Étape 2 :} Étiquetage des sous graphe en choisissant la structure $x \in \Omega$ qui représente chaque sous- graphe avec le moindre coût.
%	\STATE \textbf{Étape 3 :} Assemblage des sous graphes en utilisant des heuristiques pour sélectionner un sous-ensemble non-redondant à partir des structure candidate de l'étape 2.
%	\STATE \textbf{Sortie :} Modèle \textit{M} et son cout d'encodage.
%\end{algorithmic}
%\end{algorithm}





