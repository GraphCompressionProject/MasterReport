\documentclass[a4paper,oneside,12pt]{report}

%------------ package pour langue fr ------
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage[T1]{fontenc}
\usepackage{multicol}
\usepackage{enumitem}
\usepackage{multirow}
%------------- for embedding images----------
\usepackage{graphicx} 
\usepackage{float}
\usepackage[export]{adjustbox}
\usepackage{amsfonts,epsfig,epstopdf,titling,url,array}
\usepackage{lscape}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
%--------- pour le style de la page ----------
\usepackage[top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}

\usepackage[]{geometry}


\usepackage[french,ruled,vlined]{algorithm2e}
\usepackage[noend]{algorithmic}

%%% francisation des algorithmes 
\renewcommand{\algorithmicrequire} {\textbf{\textsc{Entrées:}}} \renewcommand{\algorithmicensure} {\textbf{\textsc{Sorties:}}} \renewcommand{\algorithmicwhile} {\textbf{tantque}} 
\renewcommand{\algorithmicdo} {\textbf{faire}} 
\renewcommand{\algorithmicendwhile}{\textbf{fin tantque}} \renewcommand{\algorithmicend} {\textbf{fin}} 
\renewcommand{\algorithmicif} {\textbf{si}} 
\renewcommand{\algorithmicendif} {\textbf{finsi}} 
\renewcommand{\algorithmicelse} {\textbf{sinon}} 
\renewcommand{\algorithmicthen} {\textbf{alors}} 
\renewcommand{\algorithmicfor} {\textbf{pour}} 
\renewcommand{\algorithmicforall} {\textbf{pour tout}}
\renewcommand{\algorithmicdo} {\textbf{faire}} 
\renewcommand{\algorithmicendfor} {\textbf{fin pour}} \renewcommand{\algorithmicloop} {\textbf{boucler}} \renewcommand{\algorithmicendloop} {\textbf{fin boucle}} \renewcommand{\algorithmicrepeat} {\textbf{répéter}} \renewcommand{\algorithmicuntil} {\textbf{jusqu'à}}
\renewcommand{\algorithmicreturn} {\textbf{Retourner}}
\renewcommand{\algorithmiccomment}[1]{\hfill$\blacktriangleright$ #1}


\usepackage{setspace}
\setstretch{1,15}
\usepackage{txfonts} %//pour utiliser times new roman dans le document
\usepackage{fancyhdr}
\fancyhf{} % clear all header and footers
\renewcommand{\headrulewidth}{0pt} % remove the header rule
\fancyfoot[RE,RO]{\thepage} % Left side on Even pages; Right side on Odd pages
\pagestyle{fancy}
\fancypagestyle{plain}{%
  \fancyhf{}%
  \renewcommand{\headrulewidth}{0pt}%
  \fancyhf[lef,rof]{\thepage}%
}
\renewcommand{\headrulewidth}{0.4pt}
\lhead{\textbf{Chapitre \thechapter}}
\fancyhead[R]{\rightmark}
%--------------------------- Sommaire ----------------------------%
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{natbib}
\theoremstyle{definition}
		\newtheorem{defn}{Definition}[section]
		\newtheorem{conj}{Conjecture}[section]
		\newtheorem{exmp}{Example}[section]
\usepackage[table,dvipsnames]{xcolor}	

\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\xmark}{\color{red}\ding{55}}%
\newcommand{\cmark}{\color{PineGreen}\ding{51}}	
\usepackage[T1]{fontenc}
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash }b{#1}}
\newcolumntype{L}[1]{>{\raggedright\arraybackslash }b{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash }b{#1}}
%\usepackage{arabtex}
\usepackage[most]{tcolorbox}


\tcbset{
    frame code={}
    center title,
    left=0pt,
    right=0pt,
    top=0pt,
    bottom=0pt,
    colback=gray!70,
    colframe=white,
    width=\dimexpr\textwidth\relax,
    enlarge left by=0mm,
    boxsep=5pt,
    arc=0pt,outer arc=0pt,
    }
% Load the package with the acronym option
\usepackage[acronym]{glossaries}
 \usepackage{appendix}
%\usepackage{setspace}

 
 
 
 
% Generate the glossary
\makeglossaries

\begin{document}

%Page de garde (page de titre)							Obligatoire
\pagenumbering{Roman}
\input{./title_psq.tex}

%Remerciements											Obligatoire
\input{./Remerciement.tex}

%Résumé												Obligatoire
\input{./abstract_psq.tex}

%Sommaire (Table des matières)							Obligatoire
\pagestyle{plain}
\tableofcontents
\newpage



%Liste des figures										Selon besoin
\listoffigures
\addcontentsline{toc}{chapter}{\numberline{}Liste des figures}
\cleardoublepage

%Liste des tableaux										Selon besoin

\listoftables
\addcontentsline{toc}{chapter}{\numberline{}Liste des tableaux}
%\cleardoublepage



\printglossaries



\cleardoublepage

%Introduction (début de la pagination)					bligatoire

\pagenumbering{arabic}

	\thispagestyle{plain}
		\Huge{ 
			\textbf {Introduction générale}} \\[0.5in]
			\addcontentsline{toc}{chapter}{\numberline{}Introduction générale}
			\normalsize
			Avec l'énorme quantité de données produites par les activités humaines de nos jours, le problème de données massives (Big data) est devenu un enjeu essentiel. Un des outils les plus efficaces pour structurer et manipuler ces données est l'utilisation des graphes. Les graphes sont des outils de modélisation utilisés dans beaucoup de domaines pour la représentation des données : réseaux sociaux et de communication (entités reliées entre elles par des liens physiques ou communautaires), chimie (relations entre les atomes), biologie (interactions entre protéines par exemple) et bien d'autres domaines.\\
			
	Face à cette infobésité, les algorithmes classiques de traitement et de gestion des donnes se montre incapable d'offrir des réponse dans un temps raisonnable. Plusieurs solution ont été pensées pour contrer ce volume de données. Une des solutions les plus anciennes mais qui connait de nouveaux défis de nos jours est \textit{la compression de données}.\\

	Le domaine de compression de données est une branche de la théorie de l'information qui s'intéresse à minimiser la taille des données à stocker, traiter et transmettre améliorant ainsi de façon directe les temps de traitement. Parallèlement à cela, nous trouvons la compression des graphes qui est un domaine dans lequel le graphe initial subit des transformations pour en obtenir une version plus réduite. Différentes techniques, basées sur différentes approches, permettent cette compression, avec ou sans perte d'information, et génèrent de nouveaux graphes sur lesquels il est beaucoup plus intéressant d'effectuer les différents traitements.\\ 

Cependant, deux types de méthodes de compression de graphes se sont distinguées parmi tout les autres types de méthodes : les méthodes de compression en utilisant les arbres k2-trees et les méthodes de compression par extraction de motifs. En effet, elles permettent de trouver dans la majorité des cas un bon compromis entre l'espace mémoire et les temps de traitement. Ces deux classe de méthodes feront l'objet de notre étude.\\
		
			Notre première contribution  portera sur la conception, l'implémentation et l'évaluation de 	deux moteurs de compression, 
		\newacronym{$k^2$-GraCE}{$k^2$-GraCE}{$k^2$-trees Graph Compression engine}	
		\newacronym{P-GraCE}{P-GraCE}{Pattern Graph Compression engine}			
			\gls{$k^2$-GraCE} 
			 et \gls{P-GraCE}, chacun englobant les méthodes relatif à une classe. Nous visons à travers cela à comparer entre leurs méthodes. Notre deuxième contribution consiste en la proposition d'une nouvelle méthode de compression pour les graphes dynamiques, s'intitulant 
			 \newacronym{ddsm}{DDSM}{Dynamic Dense Subgraph Mining}
			 \gls{ddsm}. \\
			
			
			 Nous avons hiérarchisé notre mémoire en trois grands chapitres. Le premier est une introduction au domaine de la théorie. Dans le second chapitre, nous introduisons les définitions de base du domaine de compression de données appliqué aux graphes ainsi que les différentes méthodes de compression existantes sous forme d'une classification que nous proposons. Par la suite, dans le chapitre trois, nous détaillons la conception de nos deux moteurs de compression de graphes et nous décrirons les bases théorique de notre méthode, puis nous donnons dans le chapitre quatre les détails de l'implémentation de nos moteurs. Dans le chapitre cinq nous présentons nos tests de performance et résultats .
	
	\cleardoublepage
\pagestyle{fancy}
\fancypagestyle{plain}{%
  \fancyhf{}%
  \renewcommand{\headrulewidth}{0pt}%
  \fancyhf[lef,rof]{\thepage}%
}
\renewcommand{\headrulewidth}{0.4pt}
\lhead{\textbf{Chapitre \thechapter}}
\fancyhead[R]{\rightmark}

\part{État de l'art}
%---->chapitre 01 :« cadrage du projet »
	\chapter{ Théorie des graphes}
	%%Ajouter une petite introduction pour ce chapitre
	  \input{./ChapitresPFE/TheorieDesGraphes/TheorieDesGraphes.tex}
	

%---->chapitre 02 :« »
	\chapter{Compression de graphes}
	La puissance des processeurs, de nos jours, augmente plus vite que les capacités de stockage ce qui engendre un déséquilibre entre le volume des données qu’il est possible de
traiter et de stocker. Dès lors, la réduction de la taille des données, plus formellement la compression de données, a été un domaine de recherche très active. 
		
		 Dans ce chapitre, nous allons
ouvrir un champ de réflexion en introduisant tout d’abord le domaine de compression des données et son application dans la théorie des graphes. Puis dans un second
temps, nous allons présenter une étude bibliographique sur les méthodes de compression existantes aujourd’hui et qui s'inscrivent dans l'une des deux classes de méthodes de compression: les méthodes de compression par les k2-trees et les méthodes de compression par extraction de motifs, pour finir avec une étude comparative entre elles.
	
		
		\section{Compression de données :}
		
			\input{./ChapitresPFE/CompressionDesGraphes/datacompression.tex}
		
		\section{Compression appliquée aux graphes:}
			\input{./ChapitresPFE/CompressionDesGraphes/CompressionAppliquee.tex}
			
	
			\subsection{Les types de compression:}
			\input{./ChapitresPFE/CompressionDesGraphes/TypeDeCompression.tex}
			
	
			\subsection{Les métriques d'évaluation des algorithmes de compression:}
				\input{./ChapitresPFE/CompressionDesGraphes/MOE.tex}
			
			\subsection{Classification des méthodes de compression:}
				\input{./ChapitresPFE/CompressionDesGraphes/classification.tex}
				
			\section{Compression par les arbres $K^2$-Trees}
				\input{./ChapitresPFE/k2_trees/K2-trees.tex}
				\input{./ChapitresPFE/k2_trees/SynK2.tex}
			\section{Compression par extraction de motifs}
			 Les motifs fréquents sont des connaissances extraites sur des données. Leur but est de fournir à l'utilisateur des informations non triviales, implicites, présumées non connues. Ils lui offrent ainsi une meilleure appréhension des données. Dès lors, l'extraction de motifs fréquents est  devenue une tâche importante dans la fouille de données et un thème très étudié par la communauté. Elle a aussi été vastement %%%% verifier ce mot
			 utilisée dans le domaine de compression des graphes vu qu'elle permet de ne garder que l'information utile et d'éliminer les redondances de manière efficace. En effet, nous trouvons plusieurs méthodes basées sur ce principe où nous pourrons clairement distinguer deux grandes classes : 
			 (i) les méthodes de compression basées vocabulaire
			 (ii) les méthodes de compression basées Agrégation.
			 
				Dans cette section, nous allons expliquer le principe de base de chaque classe où nous allons subdiviser chacune en plusieurs sous-classes en se basant sur ce dernier. 
				%%% a revoir le dernier paragraphe
			 
				\subsection{Compression basée vocabulaire}
				\label{vog_desc}
				Les méthodes de compression par extraction de motifs basées vocabulaire sont des méthodes qui ont attirées l'attention des chercheurs ces dernières années car elles permettent une meilleure compréhension du graphe. Elles partent toujours d'un ensemble de structures prédéfinies qui ont été prouvées fréquentes dans les graphes réels. Deux sous classes de cette dernières peuvent être identifiées :
				 
					 \textbf{Les Méthodes basées sur des techniques de clustering}
							
							Les méthodes de cette classe s'appuient sur le fait qu'on ne peut pas comprendre facilement les graphes denses, alors que quelques structures simples sont beaucoup plus faciles à comprendre et souvent très utiles pour analyser le graphe. Elles se basent sur des algorithmes de détection de communautés. 
							La question suivante peut alors se poser: pourquoi ne pas appliquer l'un des nombreux algorithmes de détection de communautés ou de partitionnement de graphes pour compresser le graphe en termes de communautés? La réponse est que ces algorithmes ne servent pas tout à fait le même objectif que la compression. Généralement, ils détectent de nombreuses communautés sans ordre explicite, de sorte qu'une procédure de sélection des sous-graphes les plus «importants» est toujours nécessaire. En plus de cela, ces méthodes renvoient simplement les communautés découvertes, sans les caractériser (par exemple, clique, étoile) et ne permettent donc pas à l'utilisateur de mieux comprendre les propriétés du graphe. 
							
							\input{./ChapitresPFE/ExtractionMotifs/EM.tex}
							\input{./ChapitresPFE/ExtractionMotifs/VOG.tex}
							\input{./ChapitresPFE/ExtractionMotifs/VOG_Overlapp.tex}
							\input{./ChapitresPFE/ExtractionMotifs/TimeCrunch.tex}
							\input{./ChapitresPFE/ExtractionMotifs/CanDense.tex}
							%\input{./Chapitres/ExtractionMotifs/SynNoeudClust.tex}
			\newpage
					 \textbf{Les méthodes basées sur les propriétés de la matrice d'adjacence}
							
							Les graphes peuvent avoir différentes représentations. Chacune des structures de données présente des avantages et des inconvénients en ce qui concerne la quantité de mémoire nécessaire pour stocker les données et la facilité d'accès aux données. Selon les besoins, il est parfois utile de stocker les données dans des structures de données plus grandes, qui nécessitent plus d'espace mais offrent un accès efficace aux données. En se basant sur ce constat plusieurs méthodes ont été  proposées dans la littérature pour compresser la matrice d'adjacence en exploitant les propriétés des graphes réels pour trouver les motifs les plus fréquents dans cette dernière.
							
							\input{./ChapitresPFE/ExtractionMotifs/intra_inter_mot_mat.tex}
							\input{./ChapitresPFE/ExtractionMotifs/mot_mat.tex}
						%	\input{./Chapitres/ExtractionMotifs/SynMatMot.tex}
					
				
				%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
				\subsection{Compression basée sur l'agrégation des motifs}
				
					Les méthodes de compression par extraction de motifs basées sur l'agrégation sont des méthodes   qui agrègent plusieurs nœuds ou liens d'un motif en un seul nœud, appelé super-nœud. Le graphe en sortie, dit super-graphe, devient dès lors plus simple et moins complexe offrant ainsi une aisance et une facilité de traitement, d'exploration et de visualisation. Nous présenterons dans ce qui suit les deux sous-classes de cette classe qui se distinguent selon que l'agrégation concerne les nœuds ou les liens.
					
					\begin{enumerate}[label=\alph*.]
				
					
					\item \subsubsection{Les méthodes de compression basées l'agrégation de nœuds}
					
					Les techniques de compression basées sur l'agrégation des nœuds des motifs sont des méthodes qui ont existé depuis plusieurs décennies offrant plusieurs avantages. 
					Elles visent à résumer le graphe initial en agrégeant les nœuds des motifs découvert dans le but de diminuer le nombre de nœuds existants  et d'offrir une meilleure visibilité et analyse du graphe. 
						
						\input{./ChapitresPFE/ExtractionMotifs/SubDue.tex}\\
						\input{./ChapitresPFE/ExtractionMotifs/GraphZip.tex}
					%	\input{./Chapitres/ExtractionMotifs/SynAgrNoeud.tex}
					
					\item \subsubsection{Les méthodes de compression basées sur l'agrégation de liens}
						Les méthodes de compression par extraction de motifs basées sur l'agrégation de liens sont parmi les méthode les plus populaires. Leur objectif est de produire un graphe compressé à partir du graphe initial en remplaçant les liens denses du graphe par un nouveau super-nœud. Elles se divisent selon le principe en deux grandes classes: celles utilisant les règles de grammaire et celles utilisant des heuristiques de clustering. Nous détaillerons dans ce qui suit ces deux classes.
						
						\begin{enumerate}[label*=\arabic*.]
							\item \textbf{Les méthodes de compression basées sur les règles de grammaire}
							La classe des méthodes de compression basées sur les règles de grammaire est une généralisation d'une méthode de compression des dictionnaires s'intitulant Re-pair. Son principe de base consiste en la  recherche, à chaque itération, de la paire de symboles la plus fréquente dans une séquence de caractères et de la remplacer par un nouveau symbole, jusqu'à ce qu'il ne soit plus commode de les remplacer. Nous notons que dans ce cas le motif est sous forme de deux arêtes ayant un sommet en commun, nommé \textit{digraph}.
								
								\input{./ChapitresPFE/ExtractionMotifs/appRep.tex}
								 %%%%exemple ???
								\input{./ChapitresPFE/ExtractionMotifs/appRepAmel.tex}
								\input{./ChapitresPFE/ExtractionMotifs/k2-partitionned.tex}
							
								\input{./ChapitresPFE/ExtractionMotifs/gRepair.tex}
								%%%%exemple ???
							%	\input{./Chapitres/ExtractionMotifs/SynGram.tex}
							\item \textbf{Les méthodes de compression basées sur des heuristiques de clustering} 				
							
							Les méthodes de compression appartenant à cette classe sont des méthodes basées sur la recherche des sous-graphes denses (ayant des nœuds fortement connectés). Elles sont destinées principalement aux graphes du Web et les graphes des réseaux sociaux dans le but de faciliter leur exploration et analyse.
								
								\input{./ChapitresPFE/ExtractionMotifs/VNM.tex}
								\input{./ChapitresPFE/ExtractionMotifs/DSM.tex}		
						
						\end{enumerate}	
					
					\end{enumerate}
						
						\input{./ChapitresPFE/ExtractionMotifs/SynGen.tex}						
								
		\section{Bilan général}
	
\input{./ChapitresPFE/CompressionDesGraphes/BillanGen.tex}

	
	
	


	
	


\part{Contribution}

%\input{./Chapitres/DDSM/ddsm.tex}

\chapter{Conception}
	\section{Introduction}
	
	La réalisation de l'étude bibliographique dans le précédent chapitre, nous a initié au domaine de compression en générale et nous a permis d'approfondir nos connaissances dans le domaine de compression des graphes. Nous avons pu voir en détails les caractéristiques de plusieurs méthodes de compression s'inscrivant dans les deux classes de méthodes de compression: celles basées sur l'extraction de motifs et celles basées sur les arbres $k^2$-tree. La vocation de ce travail est d'enrichir un projet existant en l'étendant avec deux moteurs de compression qui regroupent différentes stratégies des deux classes étudiées. La réalisation de ces deux moteurs permettra de comparer entre ces stratégies et d'avoir une idée plus claire sur leurs performances dans différents scénarios.
	
	Dans ce chapitre, nous présenterons les détails de la conception des deux moteurs. Nous allons, dans un premier temps, présenter leur principe de fonctionnement tout en mettant l'accent sur les différents modules qui les constituent. Nous expliquerons juste après notre deuxième contribution qui consiste en une nouvelle  méthode de compression destinée aux graphes dynamiques.
	

	\section{$k^2$-GraCE : }
	\label{k2}

Dans cette section, nous présenterons les détails de notre premier Moteur baptisé $k2$-GraCE pour $k^2$-trees Graph Compression Engine. Il consiste en un moteur de compression de graphes par les arbres $k^2$-trees qui exploitent les propriétés de localité et de similarité dans les graphes du web. 

		\subsection{Principe de fonctionnement :}
		
	Le moteur $k^2$-GraCE a été conçu pour permettre la compression de graphes statiques ou dynamiques et orientés ou non orientés. Il se base sur les travaux de Brisaboa et al. \citep{brisaboa2009k}. Il offre la possibilité de construire le compressé à partir de la matrice d'adjacence, de la liste d'adjacence ou du graphe directement. Il permet aussi dans le cas des graphes dynamiques de réduire davantage la taille de l'arbre en le construisant n'ont pas à partir de la matrice d'adjacence initiale mais en calculant une matrice de différence entre les instants $t_i$. 
	
	
$k^2$-GraCE est un moteur de compression sans perte de données. En effet, il construit en sortie un arbre $k^2$-tree incluant toute information présente dans le graphe initial. Cette information est représentée sous forme de deux chaines binaires. Le processus de compression d'un graphe de données par le moteur $k^2$-GraCE passe par les étapes suivantes :
\begin{enumerate}
\item Lecture et structuration du graphe de données en entrée 
\item Pré-traitement : cette étape est optionnelle, elle ne figure pas dans l'algorithme de base. 
\item Construction récursive de l'arbre k2-tree à partir de la matrice d'adjacence (resp. la liste d'adjacence) et la concaténation des différents niveaux dans une première chaine T, à l'exception du dernier niveau qui sera stocké dans une deuxième chaine L.

\item Écriture du graphe compressé sur le fichier de sortie.
\end{enumerate}

Nous illustrons ces phases par la figure \ref{k2grace} qui donne une vue globale sur le principe de fonctionnement de ce moteur.


\begin{figure}[H]
\includegraphics[scale=0.48]{./ressources/image/ograce.jpg}
\caption[Principe de fonctionnement du moteur $k^2$-GraCE]{Principe de fonctionnement du moteur $k^2$-GraCE.}
			\label{k2grace}
\end{figure}
Après avoir expliquer de manière générale le principe de fonctionnement du moteur $k^2$-GraCE, nous présenterons dans ce qui suit les détails de la phase de compression (construction de l'arbre). Nous allons tout d'abords commencer par présenter les notations et opérations de bases qui seront utilisées par la suite. Nous enchainerons par les différents algorithmes de construction selon le types de graphes en entrée.
		
		\subsection{Paramètre et notations :}
				
		\begin{table}[H]
		\centering
		\begin{tabular}{|c|L{12cm}|}
		\hline Paramètre & Signification \\ \hline\hline 
		$G$ & Graphe de données \\ \hline
		$M$ & Matrice d'adjacence du graphe G\\ \hline
		$List$ & Liste d'adjacence du graphe G\\ \hline
		$A$ & L'arbre $k^2$-tree \\\hline
		$T$ & Le nombre de instants dans lesquels le graphe a été capturé \\\hline
		$h$ & L'hauteur de l'arbre $k^2$-tree \\ \hline
		$N$ & Nombre de nœuds dans le graphe \\ \hline
		$k$ & Paramètre déterminant le nombre de fils dans l'arbre $k^2$-tree\\ \hline
		rank($T,i$) &  Fonction calculant le nombre de 1 existant dans le tableau binaire $T$ dans l'intervalle des indices [$1,i$] \\ \hline
		\end{tabular}
		\caption{Tableau des notations et paramètres du moteur $k^2$-GraCE.}	
		\label{notk2grace}		
	\end{table}
	
		\subsection{Conception Modulaire:}
		
		Dans cette partie, nous détaillerons chaque phase du processus de compression du moteur $k^2$-GraCE. Nous commencerons par présenter les différentes techniques de pré-traitement 
		que nous voulons utiliser tout au long avec notre moteur. Nous expliquerons par la suite le processus de compression pour chaque type de graphe supporter par le moteur $k^2$-GraCE et nous allons aussi fournir les différents algorithmes d'extraction de voisins en Annexe \ref{k2_annexe}. 
		
			\subsubsection{Pré-traitement du graphe de données:}
Durant cette première phase, le moteur $k^2$-GraCE utilise des stratégies qui permettrons d'aboutir à une meilleur compression. Il offre une alternative pour chaque type de graphe qu'il supporte. 		
			
			
			Dans le cas des graphes statiques orienté, $k^2$-GraCE offre la possibilité de ré-ordonnoncer les nœuds du graphe de données G.
			% Nous expliquerons  dans ce qui suit les différents algorithmes de ré-ordonnancement qui peuvent être utiliser dans notre moteur. 
			Comme notre travail est une suite d'un travail d'étudiants de l'année précédente \citep{master2017}, ce module a été déjà conçu et implémenté. Nous rappellerons uniquement dans cette section le principe de base de chaque méthode. 
			
			\begin{itemize}[label=$\bullet$]
\item\textbf{Ordre Lexicographique :} Les nœuds sont ordonnés selon leurs listes de successeurs. Les listes de successeurs seront donc triées selon un ordre croissant des identifiants et par la suite ordonnées.

	
\item\textbf{Ordre Gray :} Les nœuds sont permuter de telle sorte que deux nœuds dont l'ordre est successif différent dans au plus un voisin. 
\item\textbf{Ordre \gls{dfs} :} Les nœuds sont ordonnés selon leurs positions dans le parcours en largeur (\gls{dfs}) du graphe.  
\item\textbf{Ordre \gls{bfs} :} Les nœuds sont ordonnés selon leurs positions dans le parcours en profondeur (\gls{bfs}) du graphe. 
\item\textbf{Ordre Aléatoire :} Des permutations aléatoires des nœuds sont établies.
			
			\end{itemize}
		
	Le deuxième type de graphe supporté par le moteur $k^2$-GraCE sont les graphes statiques non orientés. Dans ce cas, nous obtenons une matrice d'adjacence symétrique. De ce fait, nous proposons de ne considérer que la partie triangulaire haute pour enlever la redondance porté par la symétrie. L'arbre construit ainsi offre toujours la possibilité d'extraire le voisinage d'un nœuds sans avoir recours à une décompression. En effet, extraire les voisins d'un nœud dans le graphe initial revient à extraire les voisins directes et inverses dans la nouvelle matrice construite en utilisant les mêmes algorithmes de l'annexe \ref{k2_annexe}.
	 Si nous prenons l'exemple du nœuds 2 dans la figure \ref{k2_non}, ses voisins sont représentés par les 1 de la deuxième ligne ou de la deuxième colonne dans la matrice d'origine (matrice gauche) et par l'union des cellules ayant un 1 de la deuxième ligne et de la deuxième colonne dans la matrice droite ce qui nous donne : $v(2) = \{1, 2, 5,6\}$.
	
\begin{figure}[H]
\centering
	\includegraphics[scale=0.4]{./ressources/image/k2_non.jpg}
	\caption[Exemple d'arbre $k^2$-tree (k=2) pour un graphe non orienté.]{Exemple d'arbre $k^2$-tree (k=2) pour un graphe non orienté.}
	\label{k2_non}
\end{figure}	


	
	$k^2$-GraCE supporte aussi les graphes dynamiques. Dans le cas de ce type de graphe, il offrent la possibilité de calculer une matrice différence à partir de la matrice initiale. Le but de cette fonctionnalité est de maximiser les zones nulles dans la matrices afin de réduire la taille de l'arbre. À t=0, on garde la même matrice bidimensionnelle du graphe initiale. Pour les instants restants (t > 0), nous comparons $M_{pq}$ à l'instant t avec $M_{pq}$ à l'instant t-1, si égalité alors la nouvelle matrice contiendra un 0 dans la cellule pq à l'instant t sinon elle contiendra un 0. La nouvelle matrice d'adjacence contiendra ainsi uniquement les changement qui occurrent entre les instants. L'inconvénient de cette fonctionnalité est qu'une reconstruction de la matrice initiale est nécessaire dans le cas d'interrogation du graphe. La figure \ref{mat_diff} montre une matrice d'adjacence d'un graphe dynamique capturé dans trois instants différents avec sa matrice de différence et la représentation $k^2$-tree dans les deux cas.

\begin{figure}[H]
\centering
	\includegraphics[scale=0.48]{./ressources/image/dynk2diff.png}
	\caption[Exemple d'arbre $k^2$-tree (k=2) pour la matrice de différence]{Exemple d'arbre $k^2$-tree (k=2) pour la matrice de différence.}
	\label{mat_diff}
\end{figure}

Nous notons que l'utilisation de ce module dans le processus de construction de l'arbre $k^2$-tree n'est pas obligatoire. Cette phase ne figure pas dans l'algorithme de base. Nous voulons, à travers son intégration dans le moteur \gls{$k^2$-GraCE}, rassembler davantage les nœuds ayant des voisins communs et donc les zones homogènes dans la matrice d'adjacence (zones plaines de 0 ou zones plaines de 1) ou augmenter le nombre de cellules nulles dans la matrice d'adjacence.
		
			\subsubsection{Construction de l'arbre $k^2$-tree}
			
			$k^2$-tree est une représentation compacte de la matrice d'adjacence qui exploite ses propriétés de dispersion et de clustering. Elle était destinée au départ pour les graphes du web et généralisée par la suite pour différents cas. La représentation est conçue pour compresser les grandes zones nulles de la matrice d'adjacence en les représentant avec un nombre réduit de bits. Plusieurs alternatives existent pour construire l'arbre $k^2$-tree: utilisation de la matrice d'adjacence, l'utilisation de la liste d'adjacence ou l'utilisation du graphe directement. Dans tous les cas, on obtiendra une représentation sous forme d'un arbre ayant une hauteur h= $log_k(N)$ où chaque nœud possède $k^2$ fils. 
			  Pour représenter l'arbre de manière concise, deux structures seront utilisées :
			\begin{itemize}
			\item \textbf{T }: Un tableau qui stocke tous les bits du $k^2$-tree sauf ceux du dernier niveau. Les bits de l' arbre $k^2$-tree sont placés après une traversée horizontale de l'arbre. $k^2$-GraCE représentent d'abord les $k^2$ valeurs binaires des enfants du nœud racine, puis les valeurs du deuxième niveau, ...etc.
			
			\item  \textbf{L} : Un tableau stockant le dernier niveau de l'arbre. Ainsi il représente la valeur de (ou certaines) cellules de la matrice d'adjacence du graphe initiale.
			\end{itemize}
			
			L'algorithme \ref{alg:k2_tree} résume les différentes étapes de construction de l'arbre $k^2$-tree dans le cas de la construction à partir de la liste d'adjacence. Nous dotons pour cela la liste d'adjacence de n curseurs, un par ligne, de sorte que chaque fois que nous devons accéder à $M_{pq}$, nous comparons le curseur actuel de la ligne $p$ à la valeur q. S'ils sont égaux, alors on aura $M_{pq} = 1$ et nous devons avancer le curseur vers le nœud suivant de la liste de la ligne p. Sinon, nous saurons que $M_{pq} = 0$. Nous supposons que la liste d'adjacence $List$, le nombre de fils $k$ ainsi que l'arbre $k^2$-tree $A$ sont des variables globales. Pour construire l'arbre à partie de la racine, elle sera invoquer comme suit :  ConstructK2Tree(N,1,0,0). Après avoir construit l'arbre $A$ sous forme d'un tableau de niveau, nous procèderons à la construction des deux structures selon les deux formules suivantes :
			\begin{itemize}[label=$\bullet$]
			 	\item T = $A_1: A_2:. . . :A_{h-1}$
			 	\item L = $A_h$
			\end{itemize}	

Des versions itératives de l'algorithme peuvent être établies. Cependant, elles dégradent les performances car elles nécessitent soit l'utilisation de structures supplémentaires ou plus d'accès mémoire. Nous avons privilégié la version récursive car elle permet de construire l'arbre $k^2$-tree en un seul parcourt de la liste d'adjacence $List$.\\

					\begin{algorithm}[H]
					\label{alg:k2_tree}
					\caption{ConstructK2Tree}
					\textbf{Entrée :}
						\begin{itemize}[label=$\bullet$]
							\item n : la taille de la sous-matrice
							\item l : le niveau de l'arbre
							\item p : l'indice ligne de début de la sous-matrice
							\item q : l'indice colonne de début de la sous-matrice
						\end{itemize}
					\textbf{Sortie :} La valeur du nœud de la sous-matrice\\							\noindent\rule{\textwidth}{1pt}
						
						
				\begin{algorithmic} [1]
					\STATE C = $ \emptyset$
					\FOR{$i = 1 ... k $} 
						\FOR{$i = 1 ... k $} 
							\IF {$l = log_k(N)$} 
								\STATE // Condition selon le type de représentation en entrée 
								\STATE // Matrice d'adjacence : M[p+i,q+j] = 1 
								\STATE // Graphe : $e_{p+i,q+j} \in E$
								\IF { $List$[p+i].courrant() = q+j }
								
									\STATE C = C : 1
									\STATE $List$[p+i].avancer()
								\ELSE
									\STATE C = C : 0
								\ENDIF
							\ELSE
								\STATE  C = C : ConstructK2Tree ( $n/k,l+1,p+i*(n/k), q+j*(n/k)$)
							\ENDIF
						\ENDFOR
					\ENDFOR
					\IF {$C\ est\ un\ vecteur\ nul$} 
						\RETURN 0
					\ENDIF
					\STATE A[l] = A[l] : C
					\RETURN 1
				\end{algorithmic}
			\end{algorithm}
	
	\newpage		
		Une fois construites, les deux structures, T et L, permettent d'extraire les voisins directes et inverses d'un nœud directement sans décompression. Nous fournissons dans l'annexe \ref{k2_annexe} les détails de ces  algorithmes d'extraction de voisinage.		
			
	

	Un autre type de graphe supporté par notre moteur sont les graphes dynamiques. Ces graphes sont représentés par un ensemble de graphes statiques chacun capturé à un instant $t_i$. De ce fait, l'algorithme de construction peut être facilement adapté avec chaque nœud dans l'arbre contenant, cette fois-ci, un vecteur de bits chacun faisant référence à un instant $t_i$. Nous fournissons ci-après (algorithme \ref{alg:dynk2_tree}) l'algorithme de construction de l'arbre $k^2$-tree à partir de la matrice d'adjacence tridimensionnelle.\\
	


	
					\begin{algorithm}[H]
					\label{alg:dynk2_tree}
					\caption{DynK2Tree}
					\textbf{Entrée :}
						\begin{itemize}[label=$\bullet$]
							\item n : la taille de la sous-matrice
							\item l : le niveau de l'arbre
							\item p : l'indice ligne de début de la sous-matrice
							\item q : l'indice colonne de début de la sous-matrice
						\end{itemize}
					\textbf{Sortie :} La valeur du nœud de la sous-matrice\\							\noindent\rule{\textwidth}{1pt}
						
						
				\begin{algorithmic} [1]
					\STATE C = $ \emptyset$
					\STATE Creturn  = $ \emptyset$
					\FOR{$i = 1 ... k $} 
						\FOR{$j = 1 ... k $} 
							\IF {$l = log_k(N)$}
								\FOR{$m = 1 ... T $}
									\STATE C[m] = C[m] : M [p+i][q+j][m]
								\ENDFOR
							\ELSE
								\STATE Ctmp =$\emptyset$
								\STATE  Ctmp = DynK2Tree ( $n/k,l+1,p+i*(n/k), q+j*(n/k)$)
								\FOR{$m = 1 ... taille(Ctmp) $}
									\STATE C[m] = C[m] : Ctmp[m]
									\STATE Creturn [m] = Creturn [m] ou Ctmp [m]
								\ENDFOR
							\ENDIF
						\ENDFOR
					\ENDFOR
					\IF {$C\ est\ un\ vecteur\ nul$} 
						\RETURN $0^{|T|}$ // retourner un vecteur nul de taille T.
					\ENDIF
					
					
					
					\FOR{$i = 1 ... k*k $} 
						\FOR{$j = 1 ... T $}
							\IF{ $C[i]$ n'est pas un vecteur nul}
								\STATE A[l] = A[l] : C [i][j]
							\ENDIF
						\ENDFOR
					\ENDFOR
	
					 \RETURN Creturn
					
				\end{algorithmic}
			\end{algorithm}
			
			
	
	
	
	\section{P-GraCE :}
	
	Notre deuxième moteur \gls{P-GraCE} est un moteur de compression par extraction de motifs. Nous présenterons dans cette partie, en détails, son principe de fonctionnement et les différents modules qui le constituent.
	
		\subsection{Principe de fonctionnement :}
		
		Les méthodes de compression par extraction de motifs sont des méthodes qui essayent de représenter le graphe de données à travers ses motifs, autrement dit ses sous-graphes portant les informations les plus importantes. 
		
		P-GraCE est un moteur de compression comportant plusieurs méthodes qui peuvent être avec ou sans perte de données. 
		En effet, le modèle produit en sortie (résultat de la compression) est parfois accompagné avec une matrice d'erreur. Le processus de compression d'un graphe de données par le moteur P-GraCE passe par les étapes suivantes :
		
\begin{enumerate}

\item Lecture et structuration du graphe de données en entrée 

\item Extraction et évaluation des motifs : Durant cette phase, une détection des motifs les plus denses ou les plus fréquents est réalisée. Leur évaluation dans cette phase permet de ne garder que les structures (motifs) susceptible de donner une meilleur compression.

\item Traitement des motifs: Ce module permet d'encoder ou d'agréger, dans certains cas, les motifs déjà découverts dans le but de minimiser d'avantage la taille du graphe en sortie. Dans d'autres cas, le module retourne une liste de structures sélectionnés parmi les motifs précédemment identifiés en utilisant des heuristiques dans le but de garder que les motifs importants du graphe. Nous notons que l'utilisation de ce module n'est pas présente dans toutes les méthodes de ce moteur mais dans la plupart 

\item Écriture du graphe compressé sur le fichier de sortie.
\end{enumerate}

La figure \ref{P_grace} permet d'illustrer le principe de fonctionnement globale du moteur \gls{P-GraCE}


\begin{figure}[H]
	\includegraphics[scale=0.48]{./ressources/image/pgrace.jpg}
	\caption[Vue globale sur le fonctionnement du moteur \gls{P-GraCE}.]{Vue globale sur le fonctionnement du moteur \gls{P-GraCE}.}
	\label{P_grace}
\end{figure}

Nous présenterons dans ce qui suit les trois modules composants le moteur P-GraCE. Nous précéderons  cela par expliquer les différents paramètres et notations que nous avons adopté durant la conception de notre deuxième moteur
		
		\subsection{Paramètre et notations :}
		
			\begin{table}[H]
		\centering
		\begin{tabular}{|c|L{12cm}|}
		\hline Paramètre & Signification \\ \hline\hline 
		$G$ & Graphe de données \\ \hline
		$V$ & L'ensemble des nœuds de G\\ \hline
		$E$ & L'ensemble des arêtes de G \\ \hline
		$L$ & L'ensemble des étiquettes de G \\ \hline
		$A$ & Matrice d'adjacence du graphe G\\ \hline
		$M$ & Le modèle produit par la compression\\ \hline
		$h$ & Heuristique d'évaluation \\ \hline
		$N$ & Nombre de nœuds dans le graphe \\ \hline
		$k$ & Paramètre déterminant le nombre de fils à considérer dans le beam-search\\ \hline
		
		\end{tabular}
		\caption{Tableau des notations et paramètres du moteur $k^2$-GraCE.}	
		\label{notk2grace}		
	\end{table}
		
		\subsection{Conception modulaire :}
		
		Durant cette section, nous allons présenter les différentes approches qui peuvent être utilisées dans chacune des phases. Nous commencerons par expliquer les méthodes d'extraction de motifs supportées par le moteur P-GraCE. Nous enchainerons avec les techniques d'évaluation que notre moteur offre, pour finir par expliquer comment ces motifs seront traités et utilisés pour compresser le graphe. 	
		
		
		\subsubsection{Extraction des motifs :}

La phase d'extraction de motifs est une phase très importante	 dans le processus de compression. Elle permet de trouver les composantes les plus denses qui représentent en générale l'information utile dans un graphe de données. Plusieurs techniques existent pour réaliser cette tache. Elles diffèrent dans la qualité de sous-structures découvertes selon le domaine d'application et le type de graphe en entrée. Nous présenterons ci-dessous les trois méthodes offertes par le moteur P-GraCE.
		
\begin{enumerate}

\item \textbf{Beam search:}\\

Le beam search est une méthode de recherche locale gloutonne. C'est une version améliorer de l'algorithme de recherche en largeur \gls{bfs}. Elle permet de n'explorer que les $k$ meilleurs fils dans chaque niveau à travers des heuristiques d'évaluation.

Dans le cas d'extraction de motifs dans un graphe, le beam search commence par considérer que chaque nœud du graphe est un motif. Il utilise pour cela un arbre de recherche où ses nœuds sont des sous-structures. À chaque itération les motifs sont étendus par une arête et un nœud donnant ainsi un ensemble de sous-structures. Par la suite, les $k$ meilleurs sous-structures sont choisies. Les fils restants sont donc élagués. %Le processus continues jusqu'à ce que
Cette alternative sera employée pour le cas des graphes étiquetés. Nous fournissons ci-après l'algorithme du beam search que nous allons utiliser. 


\begin{algorithm}[H]
					\label{alg:beamSearch}
					\caption{Beam-Search}
					\textbf{Entrée :}
						\begin{itemize}[label=$\bullet$]
							\item G : le graphe de donnée
							\item k : le nombre de fils à considérer
							\item limit : limite de la profondeur de l'arbre
						\end{itemize}
					\textbf{Sortie :} retourne la meilleur sous-structure\\							\noindent\rule{\textwidth}{1pt}
						
						
				\begin{algorithmic} [1]
					\STATE C = $\{v\ |\ v$ est un nœud ayant une unique étiquette dans  $G\}$
					\STATE $meilleurStruct$ = la première sous-structure de C
					\REPEAT
					\STATE nouvelC= $\emptyset$
					\FOR{ chaque S dans C} 
						\STATE nouvelStruct = Etendre(S)
						\STATE Evaluer(nouvelStruct)
						\STATE nouvelC = nouvelC $\cup$ \{ les k meilleur sous-structures de nouvelStruct \}
					\ENDFOR
					\STATE limit = limit -1
					\IF {$h$( meilleur sous-structure de C) <= $h$($meilleurStruct$)  }
					
					\STATE $meilleurStruct$  = meilleur sous-structure de C
					\ENDIF
					\STATE C = nouvelC
					\UNTIL{$C = \emptyset $ ou $limit \leq 0$}
					
				\end{algorithmic}
			\end{algorithm}



\item \textbf{Méthodes de clustering :}

Plusieurs méthodes de clustering existent dans la littérature. P-GraCE utilise une  méthode de clustering qui a été destinée pour compresser un graphe de données en entrée s'intitulant \textit{SlashBurn}. Cette technique parte de l'observation  que les graphes du monde réel sont facilement décomposables en supprimant leurs nœuds concentrateurs qui sont définies comme les neouds ayant un degré maximale dans le graphe G.  

Ce module de P-GraCE permet donc de réordonner les nœuds du graphe de tel sorte à avoir un plus petit nombre de blocs plus denses dans la matrice d'adjacence qui représentent les motifs en sortie.  

À chaque itération le nœud concentrateur est supprimé et le graphe est décomposé en un nœud concentrateur (hub), un
\newacronym{gcc}{CCG}{Composant Connecté Géant}
\gls{gcc} et des rayons restants que nous définissons comme étant le composant connecté non géant connecté aux anciens \gls{gcc}. Le nœud concentrateur obtient ainsi le plus petit identifiant , les nœuds des rayons (spokes) reçoivent les identifiants les plus élevés  dans l’ordre décroissant de la taille du composant connecté auquel ils appartiennent, et le nouveau \gls{gcc} prend les identifiants restants. Le même processus s'applique aux nœuds dans \gls{gcc}, de manière récursive.\\

Nous illustrons le principe de fonctionnement de cette méthode de clustering sur le graphe de la figure \ref{Img:slashb}. Le nœud concentrateur (8) obtient le plus petit identifiant (1), les nœuds des rayons reçoivent les identifiants les plus élevés (9-16), et le \gls{gcc} prend les identifiants restants (2-8). La prochaine itération considère le nouveau \gls{gcc}.

\begin{figure}[H]
	\centering
	\label{Img:slashb}
	\includegraphics[scale=0.25]{ressources/image/slashburn.png}
	\caption{Exemple d'application de l'algorithme SlashBurn}

 \end{figure}





\item \textbf{Fonctions de hachage :}

Dans cette alternative, nous allons partitionner le graphe en des motifs denses dont les nœuds sont fortement connectés. Nous utiliserons pour cela une approximation de \textit{la similarité de Jaccard} qui est une métrique permettant de mesurer la similarité entre deux ensembles $S_1$ et $S_2$ (voir formule \ref{eq:Jacc}). 

\begin{equation} \label{eq:Jacc}
SIM(S_1,S_2)=\frac{|S_1 \cap S_2|}{|S_1 \cup S_2|}
\end{equation}


L'objectif de cette méthode est de remplacer les listes d'adjacence des nœuds par des représentations beaucoup plus petites appelées « signatures ». La propriété importante de ces signatures est que leur comparaison permet d'estimer la similitude de Jaccard des listes d'adjacence sans avoir recours à les comparer deux à deux. 

Avant d'expliquer comment il est possible de construire de petites signatures à partir des listes d'adjacence, il est utile de les visualiser en tant que matrice caractéristique. Les colonnes de cette matrice correspondent aux listes d'adjacence et les lignes correspondent aux nœuds. Nous rappelons que la matrice caractéristique est peu susceptible d'être la façon dont les données sont stockées, mais elle est utile pour visualiser les données (voir figure \ref{jacc}). 


Dans un premier temps, k-permutations aléatoires des nœuds devront être choisies. L'utilisation des k-permutations se base sur le fait que :
%% Ajouter demonstration en Annexe ou donner la source 
\begin{equation} \label{eq:prob}
P(\pi_i(S_1) = \pi_j(S_2)) = \frac{|S_1 \cap S_2|}{|S_1 \cup S_2|} = SIM(S_1,S_2)
\end{equation}
Cependant, le choix de ces permutations peut être prohibitive dans le cas des grands graphes.
À la place des k-permutations, nous utiliserons donc une famille de fonctions de hachage indépendantes qui donnerons le même résultats. La famille de fonction que nous visons utiliser est une famille polynômiale : $h_{a_0, ..., a_{k-1}}(x)= (\sum a_i x^i)\ mod\ N$. Ainsi, au lieu de choisir n permutations aléatoires de lignes, nous sélectionnons n fonctions de hachage choisies de manière aléatoire $h_1, h_2,. . . , h_k$ sur les lignes. Nous construisons la matrice de signature en considérant chaque ligne dans leur ordre donné. Soit $SIG (i, c)$ l'élément de la matrice de signature pour la $i^{ème}$ fonction de hachage et la colonne c. SIG (i, c) est initialisée à $\infty$ pour tout i et c. Nous traitons une ligne r en procédant comme suit:
\begin{enumerate}
\item nous calculons $h_1 (r), h_2 (r), ..., h_k (r)$.
\item Pour chaque colonne, nous procédons comme suit: 
	\begin{itemize}
		\item  Si c a 0 dans la rangée r, rien à faire.
		\item  Cependant, si c a 1 dans la rangée r, alors pour chaque i = 1,2, ..., k  \\$SIG (i, c)$ = min( $SIG (i, c)$ , $h_i(r)$ ).
	\end{itemize}
\end{enumerate}


\end{enumerate}

Une fois les signatures sont construites, les nœuds ayant les même valeurs seront regroupés. Nous obtiendrons ainsi en sortie la liste des motifs les plus denses dans le graphe de données. Nous illustrons le principe de fonctionnement de cette stratégie sur un graphe G dans la figure \ref{jacc}. Le tableau gauche de la figure \ref{jacc} montre une matrice caractéristique des listes d'adjacence des différents nœuds du graphe G ainsi que deux permutations aléatoires $h_1$, $h_2$. Tant dis que le tableau à droite de la même figure montre les étapes de calcul des signatures en utilisant ces deux fonctions. La matrice des signatures finale montre bien que les nœuds 1 et 4 sont les plus similaires ce qui est justifié par leurs listes d'adjacence qui ne diffèrent que dans un seul élément.  

\begin{figure}[H]
\centering
	\includegraphics[scale=0.48]{./ressources/image/jacc.png}
	\caption[Exemple de calcul de la matrice des signatures.]{Exemple de calcul de la matrice des signatures.}
	\label{jacc}
\end{figure}
	
		
		\subsubsection{Évaluation des motifs :}
		
		 Dans cette deuxième phase, P-GraCE cherche à obtenir la meilleur compression en filtrant les sous-structures et ne gardant que celle qui offrent un bon \gls{mdl}. 
		 
Comme nous l'avons déjà préciser P-GraCE utilise le beam-search pour le cas des graphe  étiqueté. Il est fondamentalement guidé par le principe \gls{mdl}. L'évaluation heuristique effectuée par le \gls{mdl} suppose que la meilleure sous-structure est celle qui minimise le \gls{mdl} du graphe en entrée lorsqu'il est compressé par cette sous-structure. Notons la longueur de description de S est représentée par DL (S), la longueur de description du graphe d'entrée G par représentée par DL (G) et la longueur de description du graphe après compression par DL (G | S). L'heuristique est alors rien d'autre que le taux de compression et peut être définie ainsi :
		 
		\begin{center}
		compression = $\frac{DL(S)+DL(G|S)} {DL(G)}$
		\end{center}
		 
   
		 
		  Dans le cas de l'utilisation des méthodes de clustering, nous obtenons une liste des structures les plus fréquentes. Pour chaque structure identifiée nous cherchons le motif qui la décrit le mieux en se basant sur un ensemble prédéfini de motifs (étoile, clique, noyau bipartie, semi clique, semi noyau bipartie). Afin de trouver le motif approximatif de la structure, nous utiliserons les formules proposées dans \citep{koutra2015summarizing} (voir section \ref{vog_desc}).
		  
		   
		\subsubsection{Traitement des motifs :}
		
		Nous proposons pour traiter les motifs deux alternatives dans le moteur P-GraCE. La première consiste à faire une agrégation des nœuds du meilleur motif. Les trois étapes seront donc répétées jusqu'à ce que la taille du graphe en sortie ne peut plus être optimisée. La deuxième alternative consiste à considérer que la liste des sous-structures de l'étape 2 représentent le compressé du graphe de données. Nous offrons dans ce cas la possibilité d'utiliser le codage proposé dans \citep{liu2018reducing}. Il représente cette liste de motifs de manière concise tout en permettant les requêtes d'extraction de voisinage. Dans certains méthodes une matrice d'erreur est conservée avec la liste des structures pour une compression sans perte.
		
		
		
	\section{Notre méthode: Dynamic Dense Subgraph Mining (DDSM)}
		\input{./ChapitresPFE/DDSM/ddsm.tex}
	
	\section{Conclusion}

Dans ce chapitre, nous avons expliqué la partie conceptuelle de nos deux moteurs: $k^2$-GraCE et P-GraCE, qui se représentent les deux classes qui intéressent notre recherche. Nous avons présenter leurs différents modules et fonctionnalités tout en clarifiant leurs paramètres ainsi que leurs principe de fonctionnement.

	Dans le chapitres suivant, nous présenteront les choix d'implémentation que nous avons effectué. Nous décrirons l'environnement de développement ainsi que l'architecture globale de notre projet. 
	
	
	
	
	
\chapter{Implémentation}
	\section{Introduction}
	
	Notre projet s'intègrent dans un projet de recherche scientifique. De ce fait, une implémentation efficace et optimisée de notre conception est nécessaire. Nous commencerons ce chapitre par présenter l'architecture existante et comment nous l'avons étendue avec nos deux moteurs tout en détaillant les différentes couches de la nouvelle architecture. Nous conclurons par présenter l'environnement de développement.
	
	
	\section{Architecture globale}
	
	L'architecture existante est une architecture en pipeline de 3-tiers. Elle se compose de trois couches logicielles que nous avons enrichie avec nos deux moteurs et la couche présentation. Nous les présenterons ci-dessous:
	
	\begin{enumerate}
	\item \textbf{La couche données ou persistance :} cette couche est responsable de la gestion des données en entrée et les fonctions d'accès et de stockage. Les données en entrées ainsi que les résultats de compression sont sous forme de fichiers.
	
	\item \textbf{La couche traitement :} c'est le noyau des moteur de compression de notre projet. Elle inclue tout les algorithmes de compression et de manipulation des graphes. 
	\item \textbf{La couche présentation :} cette couche permet de faciliter l'utilisation de notre solution à travers une interface simple et intuitive.
	\end{enumerate}
	
	
	
\begin{figure}[H]
	\centering
	\label{Img:archglob}
	\includegraphics[scale=0.35]{ressources/image/ArchGlob.jpg}
	\caption{Architecture globale de la solution}

 \end{figure}
	
	
	
	\section{Données}
	Les données manipulées par notre solution sont tous sous format de fichiers textes. La structure de ses fichiers diffèrent selon le type de graphe en entrée. Comme nous l'avons déjà implicitement mentionnées, notre solution prend en charge les types de graphes suivant : graphe dynamique orienté, graphe statique orienté, graphe statique non orienté et finalement graphe statique étiqueté. Nous présenterons dans ce qui suit ses structures de fichiers:
	
	\begin{itemize}[label=$\bullet$]
	\item 1
	\item 2
	\item 3
	\item 4
	
	\end{itemize}
	
	
	
	\section{Traitement}
	\section{Présentation}
	
	La couche présentation est responsable de donner accès à toutes les fonctionnalités offertes par notre solution, entre autres le choix des paramètres pour différentes méthodes, ainsi que de visualiser les résultats. En plus du fichier de sortie, elle fournit les différentes mesures de performances. Elle offre ainsi aux chercheurs la possibilité de comparer les performances de différents méthodes sur un même graphe. Cette couche permet d'utiliser notre solution sans avoir recours à chaque fois au guide d'utilisation pour trouver les commandes d'exécution.
	
	\section{Environnement de développement}
		
		Le choix des outils de développement dans tout projet informatique est très important vue leur fort impact sur les performances du produit finale. Comme notre solution fait partie d'un projet de recherche, il faut aussi prendre en compte la flexibilité et la capacité de la solution à s'interfacer avec d'autre outils dans des systèmes qui peuvent être hétérogènes. 
		
		\subsection{Langage de Programmation}
		Nous avons adopté le langage de programmation avec lequel la    première version de notre solution a été développée: le C++. En effet, le langage C++ est un langage très performants pour les calculs lourds. Il permet d'avoir des exécutions très rapides, ce qui en fait un langage de choix pour les applications critiques qui ont besoin de performances. Il permet aussi d'avoir un code portable : un même code source peut être facilement transformé en exécutable sous Windows, Mac OS ou Linux. Un autre aspect du langage c++ est sa richesse de bibliothèques optimisées pour le traitement et le stockage des grands graphes en mémoire. 
		
		Nous avons choisi Visual Studio 2015 comme environnement de développement (IDE). Notre choix a été influencé par le fait que Visual Studio s'ouvre à toutes les tendances du moment et permet facilement de travailler en équipe sur le même projet.
		
		\newacronym{ide}{IDE}{Integrated Developement Environement} 
		\subsection{Bibliothèque Snap}
		
		\newacronym{snap}{SNAP}{Stanford Network Analysis Package}		
		Afin de faciliter la manipulation des graphes et d'améliorer les performances de notre solution, nous avons offert la possibilité d'exécuter les différents algorithmes de compression en utilisant une des plus performantes bibliothèque de manipulation de graphes en c++ : SNAP.
		\gls{snap} est une bibliothèque d'analyse et d'exploration de graphes à usage général qui s'adapte facilement à des graphes massives. Elle présente aussi l'avantage d'être  efficace et facilement extensible. Elle prend naturellement en charge les graphes riches avec des types de données complexes associés aux nœuds et aux arêtes. 
		
		\subsection{Bibliothèque Boost}
		

Boost est un ensemble de bibliothèques pour le langage de programmation C ++ qui prend en charge des tâches et des structures telles que l'algèbre linéaire, la génération de nombres pseudo-aléatoires, le multithreading, les expressions régulières et les tests unitaires. Elle contient plus de quatre vingt bibliothèques individuelles.

Nous l'avons utilisées dans notre projet pour l'implémentation des arbres $k^2$-trees. En effet, elle contient une implémentation des tableaux de bits en c++ qui donnent un temps d'exécution optimale parmi toutes les autres implémentations existantes \citep{pieterse2010performance}.  



		\subsection{Bibliothèque Qt }
	\section{Conclusion}
	
Durant ce chapitre, nous avons présenté notre implémentation où nous avons essayer d'utiliser différentes bibliothèques permettant d'avoir de meilleurs performances. L'indépendance des différentes couches de l'architecture existantes nous ont faciliter la tache d'implémentation. Nous avons ainsi essayer de respecter cette indépendance afin de faciliter tout autre contribution future dans le projet. 

Nous évaluerons dans le chapitre suivant les différentes méthodes de nos deux moteurs en vue de l'obtention d'une étude comparative plus objective et plus clair.



\chapter{Test}
	\section{Introduction}
	\section{Environnement de Test}
	\section{Présentation des graphes de test}
	\section{Évaluation du moteur $k^2$-GraCE}
			\subsection{Analyse de l'impact du paramètre k}
			\subsection{Étude de l'effet de l'ordre}
			
	\section{Évaluation du moteur P-GraCE}
	
	\section{Comparaison entre les différents moteurs}
	
	\section{Conclusion}

\chapter{Conclusion Générale}








\pagestyle{plain}
\newpage

\begin{appendix}


\chapter{Extraction de voisins dans un arbre $k^2$-tree}
    \label{k2_annexe}
La compression par les arbres $k^2$-trees a connue un large succès dans la communauté scientifique. L'une des causes les plus importantes qui ont favorisé cela est qu'elle permet d'extraire le voisinage des nœuds sans reconstitution du graphe initiale. Cette partie se veut une explication des deux algorithmes d'extraction de voisins directes et inverses. 

Comme nous l'avons déjà expliqué dans la section \ref{k2} de la partie conception   du moteur $k^2$-GraCE, les arbres $k^2$-tree sont représentés en mémoire à l'aide de deux chaines binaires, T et L, qui regroupe le contenue de l'arbre de haut vers le bas et de la gauche vers la droite. Nous fournissons ci-après les algorithmes d'extraction de voisinage \citep{brisaboa2009k}.



\begin{multicols}{2}

\begin{algorithm}[H]
					\label{alg:Direct}
					\caption{Direct}
					\textbf{Entrée :}
						\begin{itemize}[label=$\bullet$]
							\item n : la taille de la sous-matrice
							\item p : l'indice de la ligne 
							\item q : l'indice de la colonne
							\item x : l'indice dans l'arbre
						\end{itemize}
					\textbf{Sortie :} affichage des voisins Directes\\							\noindent\rule{\textwidth}{1pt}
						
						
				\begin{algorithmic} [1]
					\IF {x $\geqslant$ |T|}
						\IF { L[x-|T|] =1 }
							\STATE afficher q
						\ENDIF
					\ELSE
						\IF { x = -1 ou T[x]=1  }
							\STATE y = rank(T,x)*$k^2$ + p/(n/k)
							\FOR{ j =0 ... k-1}
								\STATE Direct(n/k,p mod(n/k),q+ j*(n/k),y+j)
							\ENDFOR
						\ENDIF
					\ENDIF 
					
					
				\end{algorithmic}
			\end{algorithm}


 
\columnbreak
 
\begin{algorithm}[H]
					\label{alg:Inverse}
					\caption{Inverse}
					\textbf{Entrée :}
						\begin{itemize}[label=$\bullet$]
							\item n : la taille de la sous-matrice
							\item q : l'indice de la colonne
							\item p : l'indice de la ligne 
							\item x : l'indice dans l'arbre
						\end{itemize}
					\textbf{Sortie :} affichage des voisins Inverses\\							\noindent\rule{\textwidth}{1pt}
						
						
				\begin{algorithmic} [1]
					\IF {x $\geqslant$ |T|}
						\IF { L[x-|T|] =1 }
							\STATE afficher p
						\ENDIF
					\ELSE
						\IF { x = -1 ou T[x]=1  }
							\STATE y = rank(T,x)*$k^2$ + q/(n/k)
							\FOR{ j =0 ... k-1}
								\STATE Inverse(n/k,q mod(n/k),p+ j*(n/k),y+j*k)
							\ENDFOR
						\ENDIF
					\ENDIF 
					
					
				\end{algorithmic}
			\end{algorithm}
			
\end{multicols}

\chapter{Description des graphes de test}
 \label{tableau des graphes de test}
 \begin{table}[H]
 \begin{tabular}{|C{5cm}|C{4.5cm}|C{4.5cm}|}
		\hline
		\multirow{2}{*}{Graphe de test} & \multicolumn{2}{c|}{Caractéristiques}  \\ \cline{2-3}
				&  Nombre de nœuds & Nombre de liens  \\ \hline	 \hline	
 
eu-2005 & 862 milles de nœuds & 19M de liens \\ \hline
Cond-mat & 36 milles de nœuds & 171 milles de liens \\ \hline
CommNet & \multicolumn{2}{c|}{taille : 225.9MB} \\ \hline
SalesDay & 1 milles de nœuds & \\ \hline
Movielens10M & 10 milles de nœuds & 10M de liens \\ \hline
ASOregon &  13 milles nœuds & 37 milles liens \\ \hline
 Enron &  80 milles nœuds& 288 milles liens \\ \hline
 uk-2002 & 18 milles nœuds & 298 milles liens \\ \hline
 graphe test de GCUPMT &  8 192 milles nœuds & \\ \hline
 Composante chimique &  21 étiquettes & 422 transactions \\ \hline
 NotreDame &  325 milles de nœuds & 1M de liens \\ \hline



\end{tabular}
									\caption{Graphes de test}									\label{comgen}

 								\end{table}
\end{appendix}






\newpage




\bibliographystyle{apalike}
\bibliography{Bibliographie}


\end{document}

%\renewcommand{\thefigure}{\arabic{figure}}
%\setcounter{figure}{0}
%\begin{figure}[H]
%	\centering
%	\includegraphics[scale=1]{ressources/image/LAAS-2016.jpg}
%	\label{fig:figure1}
%	\caption{This is a teste of figure}
	
%\end{figure}








