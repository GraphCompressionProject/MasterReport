\documentclass[a4paper,oneside,12pt]{report}

%------------ package pour langue fr ------
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage[T1]{fontenc}
\usepackage{multicol}
\usepackage{enumitem}
\usepackage{multirow}
\setcounter{secnumdepth}{5} 
%------------- for embedding images----------
\usepackage{graphicx} 
\usepackage{float}
\usepackage[export]{adjustbox}
\usepackage{amsfonts,epsfig,epstopdf,titling,url,array}
\usepackage{lscape}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
%--------- pour le style de la page ----------
\usepackage[top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}

\usepackage[]{geometry}


\usepackage[french,ruled,vlined]{algorithm2e}
\usepackage[noend]{algorithmic}

%%% francisation des algorithmes 
\renewcommand{\algorithmicrequire} {\textbf{\textsc{Entrées:}}} \renewcommand{\algorithmicensure} {\textbf{\textsc{Sorties:}}} \renewcommand{\algorithmicwhile} {\textbf{tantque}} 
\renewcommand{\algorithmicdo} {\textbf{faire}} 
\renewcommand{\algorithmicendwhile}{\textbf{fin tantque}} \renewcommand{\algorithmicend} {\textbf{fin}} 
\renewcommand{\algorithmicif} {\textbf{si}} 
\renewcommand{\algorithmicendif} {\textbf{finsi}} 
\renewcommand{\algorithmicelse} {\textbf{sinon}} 
\renewcommand{\algorithmicthen} {\textbf{alors}} 
\renewcommand{\algorithmicfor} {\textbf{pour}} 
\renewcommand{\algorithmicforall} {\textbf{pour tout}}
\renewcommand{\algorithmicdo} {\textbf{faire}} 
\renewcommand{\algorithmicendfor} {\textbf{fin pour}} \renewcommand{\algorithmicloop} {\textbf{boucler}} \renewcommand{\algorithmicendloop} {\textbf{fin boucle}} \renewcommand{\algorithmicrepeat} {\textbf{répéter}} \renewcommand{\algorithmicuntil} {\textbf{jusqu'à}}
\renewcommand{\algorithmicreturn} {\textbf{Retourner}}
\renewcommand{\algorithmiccomment}[1]{\hfill$\blacktriangleright$ #1}



\usepackage{setspace}
\setstretch{1,15}
\usepackage{txfonts} %//pour utiliser times new roman dans le document
\usepackage{fancyhdr}
\fancyhf{} % clear all header and footers
\renewcommand{\headrulewidth}{0pt} % remove the header rule
\fancyfoot[RE,RO]{\thepage} % Left side on Even pages; Right side on Odd pages
\pagestyle{fancy}	
\fancypagestyle{plain}{%
  \fancyhf{}%
  \renewcommand{\headrulewidth}{0pt}%
  \fancyhf[lef,rof]{\thepage}%
}
\renewcommand{\headrulewidth}{0.4pt}
\lhead{\textbf{Chapitre \thechapter}}
\fancyhead[R]{\rightmark}
%--------------------------- Sommaire ----------------------------%
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{natbib}
\theoremstyle{definition}
		\newtheorem{defn}{Definition}[section]
		\newtheorem{conj}{Conjecture}[section]
		\newtheorem{exmp}{Example}[section]
\usepackage[table,dvipsnames]{xcolor}	

\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\xmark}{\color{red}\ding{55}}%
\newcommand{\cmark}{\color{PineGreen}\ding{51}}	
\usepackage[T1]{fontenc}
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash }b{#1}}
\newcolumntype{L}[1]{>{\raggedright\arraybackslash }b{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash }b{#1}}
%\usepackage{arabtex}
\usepackage[most]{tcolorbox}


\tcbset{
    frame code={}
    center title,
    left=0pt,
    right=0pt,
    top=0pt,
    bottom=0pt,
    colback=gray!70,
    colframe=white,
    width=\dimexpr\textwidth\relax,
    enlarge left by=0mm,
    boxsep=5pt,
    arc=0pt,outer arc=0pt,
    }
% Load the package with the acronym option
\usepackage[acronym]{glossaries}
\usepackage{appendix}
%\usepackage{setspace}
\usepackage{subfig}
 
 
 
 
% Generate the glossary
\makeglossaries
\usepackage{pdfpages} 
\begin{document}

%Page de garde (page de titre)							Obligatoire
\pagenumbering{Roman}
\input{./title_psq.tex}

%Remerciements											Obligatoire
\input{./Remerciement.tex}

%Résumé												Obligatoire
\input{./abstract_psq.tex}
 \includepdf[page=-]{psq_absract_ar}

%Sommaire (Table des matières)							Obligatoire
\pagestyle{plain}
\tableofcontents
\newpage



%Liste des figures										Selon besoin
\listoffigures
\addcontentsline{toc}{chapter}{\numberline{}Liste des figures}
\cleardoublepage

%Liste des tableaux										Selon besoin

\listoftables
\addcontentsline{toc}{chapter}{\numberline{}Liste des tableaux}
%\cleardoublepage



\printglossaries



\cleardoublepage

%Introduction (début de la pagination)					bligatoire

\pagenumbering{arabic}

	\thispagestyle{plain}
		\Huge{ 
			\textbf {Introduction générale}} \\[0.5in]
			\addcontentsline{toc}{chapter}{\numberline{}Introduction générale}
			\normalsize
			Avec l'énorme quantité de données produites par les activités humaines de nos jours, le problème de données massives (Big data) est devenu un enjeu essentiel. Un des outils les plus efficaces pour structurer et manipuler ces données est l'utilisation des graphes. Les graphes sont des outils de modélisation utilisés dans beaucoup de domaines pour la représentation des données : réseaux sociaux et de communication (entités reliées entre elles par des liens physiques ou communautaires), chimie (relations entre les atomes), biologie (interactions entre protéines par exemple) et bien d'autres domaines.\\
			
	Face à cette infobésité, les algorithmes classiques de traitement et de gestion des données se montrent incapables d'offrir des réponses dans un temps raisonnable. Plusieurs solutions ont été pensées pour contrer ce volume de données. Une des solutions les plus anciennes mais qui connait de nouveaux défis de nos jours est la \textit{ compression de données}.\\

	Le domaine de compression de données est une branche de la théorie de l'information qui s'intéresse à minimiser la taille des données à stocker, traiter et transmettre améliorant ainsi de façon directe les temps de traitement. Parallèlement à cela, nous trouvons la compression des graphes qui est un domaine dans lequel le graphe initial subit des transformations pour en obtenir une version plus réduite. Différentes techniques, basées sur différentes approches, permettent cette compression, avec ou sans perte d'information, et génèrent de nouveaux graphes sur lesquels il est beaucoup plus intéressant d'effectuer les différents traitements.\\ 

Cependant, deux types de méthodes de compression de graphes se sont distinguées parmi tout les autres types de méthodes : les méthodes de compression en utilisant les arbres k2-trees et les méthodes de compression par extraction de motifs. En effet, elles permettent de trouver dans la majorité des cas un bon compromis entre l'espace mémoire et les temps de traitement. Ces deux classes de méthodes feront l'objet de notre étude.\\
		
			Notre première contribution  portera sur la conception, l'implémentation et l'évaluation de 	deux moteurs de compression, 
		\newacronym{$k^2$-GraCE}{$k^2$-GraCE}{$k^2$-trees Graph Compression engine (Moteur de compression des graphes par les arbres $k^2$-trees )}	
		\newacronym{P-GraCE}{P-GraCE}{Pattern Graph Compression engine (Moteur de compression des graphes par extraction de motifs)}			
			\gls{$k^2$-GraCE} 
			 et \gls{P-GraCE}, chacun englobant les méthodes relatives à une classe. Nous visons à travers cela à comparer entre les performances des méthodes s'intégrant dans ces deux classes. Notre deuxième contribution consiste en la proposition d'une nouvelle méthode de compression pour les graphes dynamiques, s'intitulant 
			 \newacronym{ddsm}{DDSM}{Dynamic Dense Subgraph Mining (Compression de graphe sous-graphes denses dynamiques) }
			 \gls{ddsm}. \\
			
			
			 Nous avons hiérarchisé notre mémoire en cinq grands chapitres. Le premier est une introduction au domaine de la théorie des graphes. Dans le second chapitre, nous introduisons les définitions de base du domaine de compression de données appliqué aux graphes ainsi que les différentes méthodes de compression existantes sous forme d'une classification que nous proposons. Par la suite, dans le troisième chapitre , nous détaillons la conception de nos deux moteurs de compression de graphes et nous décrirons les bases théoriques de notre méthode, puis nous donnons dans le quatrième chapitre  les détails de l'implémentation que nous proposons. Finalement, nous présentons dans le dernier chapitre les différents tests de performance et les résultats obtenus.
	
	\cleardoublepage
\pagestyle{fancy}
\fancypagestyle{plain}{%
  \fancyhf{}%
  \renewcommand{\headrulewidth}{0pt}%
  \fancyhf[lef,rof]{\thepage}%
}
\renewcommand{\headrulewidth}{0.4pt}
\lhead{\textbf{Chapitre \thechapter}}
\fancyhead[R]{\rightmark}

\part{Synthèse bibliographique}
%---->chapitre 01 :« cadrage du projet »
	\chapter{ Théorie des graphes}
	%%Ajouter une petite introduction pour ce chapitre
	  \input{./ChapitresPFE/TheorieDesGraphes/TheorieDesGraphes.tex}
	

%---->chapitre 02 :« »
	\chapter{Compression de graphes}
	La puissance des processeurs, de nos jours, augmente plus vite que les capacités de stockage ce qui engendre un déséquilibre entre le volume des données qu'il est possible de
traiter et de stocker. Dès lors, la réduction de la taille des données, plus formellement la compression de données, a été un domaine de recherche très active. 
		
		 Dans ce chapitre, nous allons tout d’abord introduire le domaine de compression des données et son application dans la théorie des graphes. Puis dans un second
temps, nous allons présenter une étude bibliographique sur les méthodes de compression existantes  et qui s'inscrivent dans l'une des deux classes de méthodes de compression: les méthodes de compression par les k2-trees et les méthodes de compression par extraction de motifs, pour finir avec une étude comparative entre elles.
	
		
		\section{Compression de données :}
		
			\input{./ChapitresPFE/CompressionDesGraphes/datacompression.tex}
		
		\section{Compression appliquée aux graphes:}
			\input{./ChapitresPFE/CompressionDesGraphes/CompressionAppliquee.tex}
			
	
			\subsection{Les types de compression:}
			\input{./ChapitresPFE/CompressionDesGraphes/TypeDeCompression.tex}
			
	
			\subsection{Les métriques d'évaluation des algorithmes de compression:}
				\input{./ChapitresPFE/CompressionDesGraphes/MOE.tex}
			
			\subsection{Classification des méthodes de compression:}
				\input{./ChapitresPFE/CompressionDesGraphes/classification.tex}
				
			\section{Compression par les arbres $K^2$-Trees}
				\input{./ChapitresPFE/k2_trees/K2-trees.tex}
				\input{./ChapitresPFE/k2_trees/SynK2.tex}
			\section{Compression par extraction de motifs}
			 Les motifs fréquents sont des connaissances extraites sur des données. Leur but est de fournir à l'utilisateur des informations non triviales, implicites, présumées non connues. Ils lui offrent ainsi une meilleure appréhension des données. Dès lors, l'extraction de motifs fréquents est  devenue une tâche importante dans la fouille de données et un thème très étudié par la communauté. Elle a aussi été vastement %%%% verifier ce mot
			 utilisée dans le domaine de compression des graphes vu qu'elle permet de ne garder que l'information utile et d'éliminer les redondances de manière efficace. En effet, nous trouvons plusieurs méthodes basées sur ce principe où nous pourrons clairement distinguer deux grandes classes : 
			 (i) les méthodes de compression basées vocabulaire
			 (ii) les méthodes de compression basées agrégation.
			 
				Dans cette section, nous allons expliquer le principe de base de chaque classe et nous allons subdiviser chacune en plusieurs sous-classes en se basant sur ce dernier. 
				%%% a revoir le dernier paragraphe
			 
				\subsection{Compression basée vocabulaire}
				\label{vog_desc}
				Les méthodes de compression par extraction de motifs basées vocabulaire sont des méthodes qui ont attirées l'attention des chercheurs ces dernières années car elles permettent une meilleure compréhension du graphe. Elles partent toujours d'un ensemble de structures prédéfinies qui ont été prouvées fréquentes dans les graphes réels. Deux sous classes de cette dernières peuvent être identifiées :
				 
					 \textbf{Les Méthodes basées sur des techniques de clustering}
							
							Les méthodes de cette classe s'appuient sur le fait qu'on ne peut pas comprendre facilement les graphes denses, alors que quelques structures simples sont beaucoup plus faciles à comprendre et souvent très utiles pour analyser le graphe. Elles se basent sur des algorithmes de détection de communautés. 
							La question suivante peut alors se poser: pourquoi ne pas appliquer l'un des nombreux algorithmes de détection de communautés ou de partitionnement de graphes pour compresser le graphe en termes de communautés? La réponse est que ces algorithmes ne servent pas tout à fait le même objectif que la compression. Généralement, ils détectent de nombreuses communautés sans ordre explicite, de sorte qu'une procédure de sélection des sous-graphes les plus «importants» est toujours nécessaire. En plus de cela, ces méthodes renvoient simplement les communautés découvertes, sans les caractériser (par exemple, clique, étoile) et ne permettent donc pas à l'utilisateur de mieux comprendre les propriétés du graphe. 
							
							%\input{./ChapitresPFE/ExtractionMotifs/EM.tex}
							\input{./ChapitresPFE/ExtractionMotifs/VOG.tex}
							\input{./ChapitresPFE/ExtractionMotifs/VOG_Overlapp.tex}
							\input{./ChapitresPFE/ExtractionMotifs/TimeCrunch.tex}
							\input{./ChapitresPFE/ExtractionMotifs/CanDense.tex}
							%\input{./Chapitres/ExtractionMotifs/SynNoeudClust.tex}
		
					 \textbf{Les méthodes basées sur les propriétés de la matrice d'adjacence}
							
							Les graphes peuvent avoir différentes représentations. Chacune des structures de données présente des avantages et des inconvénients en ce qui concerne la quantité de mémoire nécessaire pour stocker les données et la facilité d'accès aux données. Selon les besoins, il est parfois utile de stocker les données dans des structures de données plus grandes, qui nécessitent plus d'espace mais offrent un accès efficace aux données. En se basant sur ce constat plusieurs méthodes ont été  proposées dans la littérature pour compresser la matrice d'adjacence en exploitant les propriétés des graphes réels pour trouver les motifs les plus fréquents dans cette dernière.
							
							\input{./ChapitresPFE/ExtractionMotifs/intra_inter_mot_mat.tex}
							\input{./ChapitresPFE/ExtractionMotifs/mot_mat.tex}
						%	\input{./Chapitres/ExtractionMotifs/SynMatMot.tex}
					
				
				%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
				\subsection{Compression basée sur l'agrégation des motifs}
				
					Les méthodes de compression par extraction de motifs basées sur l'agrégation sont des méthodes   qui agrègent plusieurs nœuds ou liens d'un motif en un seul nœud, appelé super-nœud. Le graphe en sortie, dit super-graphe, devient dès lors plus simple et moins complexe offrant ainsi une aisance et une facilité de traitement, d'exploration et de visualisation. Nous présenterons dans ce qui suit les deux sous-classes de cette classe qui se distinguent selon que l'agrégation concerne les nœuds ou les liens.
					
					\begin{enumerate}[label=\alph*.]
				
					
					\item \subsubsection{Les méthodes de compression basées l'agrégation de nœuds}
					
					Les techniques de compression basées sur l'agrégation des nœuds des motifs sont des méthodes qui ont existé depuis plusieurs décennies offrant plusieurs avantages. 
					Elles visent à résumer le graphe initial en agrégeant les nœuds des motifs découvert dans le but de diminuer le nombre de nœuds existants  et d'offrir une meilleure visibilité et analyse du graphe. 
						
						\input{./ChapitresPFE/ExtractionMotifs/SubDue.tex}\\
						\input{./ChapitresPFE/ExtractionMotifs/GraphZip.tex}
					%	\input{./Chapitres/ExtractionMotifs/SynAgrNoeud.tex}
					
					\item \subsubsection{Les méthodes de compression basées sur l'agrégation de liens}
						Les méthodes de compression par extraction de motifs basées sur l'agrégation de liens sont parmi les méthode les plus populaires. Leur objectif est de produire un graphe compressé à partir du graphe initial en remplaçant les liens denses du graphe par un nouveau super-nœud. Elles se divisent selon le principe en deux grandes classes: celles utilisant les règles de grammaire et celles utilisant des heuristiques de clustering. Nous détaillerons dans ce qui suit ces deux classes.
						
						\begin{enumerate}[label*=\arabic*.]
							\item \textbf{Les méthodes de compression basées sur les règles de grammaire}
							La classe des méthodes de compression basées sur les règles de grammaire est une généralisation d'une méthode de compression des dictionnaires s'intitulant Re-pair. Son principe de base consiste en la  recherche, à chaque itération, de la paire de symboles la plus fréquente dans une séquence de caractères et de la remplacer par un nouveau symbole, jusqu'à ce qu'il ne soit plus commode de les remplacer. Nous notons que dans ce cas le motif est sous forme de deux arêtes ayant un sommet en commun, nommé \textit{digraph}.
								
								\input{./ChapitresPFE/ExtractionMotifs/appRep.tex}
								 %%%%exemple ???
								\input{./ChapitresPFE/ExtractionMotifs/appRepAmel.tex}
								\input{./ChapitresPFE/ExtractionMotifs/k2-partitionned.tex}
							
								\input{./ChapitresPFE/ExtractionMotifs/gRepair.tex}
								%%%%exemple ???
							%	\input{./Chapitres/ExtractionMotifs/SynGram.tex}
							\item \textbf{Les méthodes de compression basées sur des heuristiques de clustering} 				
							
							Les méthodes de compression appartenant à cette classe sont des méthodes basées sur la recherche des sous-graphes denses (ayant des nœuds fortement connectés). Elles sont destinées principalement aux graphes du Web et les graphes des réseaux sociaux dans le but de faciliter leur exploration et analyse.
								
								\input{./ChapitresPFE/ExtractionMotifs/VNM.tex}
								\input{./ChapitresPFE/ExtractionMotifs/DSM.tex}		
						
						\end{enumerate}	
					
					\end{enumerate}
						
						\input{./ChapitresPFE/ExtractionMotifs/SynGen.tex}						
								
		\section{Conclusion}
	
\input{./ChapitresPFE/CompressionDesGraphes/BillanGen.tex}

	
	
	


	
	


\part{Contribution}

%\input{./Chapitres/DDSM/ddsm.tex}

\chapter{Conception}
	\section{Introduction}
	
	La réalisation de l'étude bibliographique dans le précédent chapitre, nous a initié au domaine de compression en général, et nous a permis d'approfondir nos connaissances dans le domaine de compression des graphes. Nous avons pu voir en détails les caractéristiques de plusieurs méthodes de compression s'inscrivant dans les deux classes de méthodes de compression: celles basées sur l'extraction de motifs et celles basées sur les arbres $k^2$-trees. La vocation de ce travail est d'enrichir un projet existant en l'étendant avec deux moteurs de compression qui regroupent différentes stratégies des deux classes étudiées. La réalisation de ces deux moteurs permettra de comparer entre ces stratégies et d'avoir une idée plus claire sur leurs performances dans différents scénarios.
	
	Dans ce chapitre, nous présenterons les détails de la conception des deux moteurs. Nous allons, dans un premier temps, présenter leur principe de fonctionnement tout en mettant l'accent sur les différents modules qui les constituent. Nous expliquerons juste après notre deuxième contribution qui consiste en une nouvelle  méthode de compression destinée aux graphes dynamiques.
	

	\section{$k^2$-GraCE : }
	\label{k2}

Dans cette section, nous présenterons  notre premier moteur baptisé \gls{$k^2$-GraCE}. Il consiste en un moteur de compression des graphes par les arbres $k^2$-trees qui exploitent les propriétés de localité et de similarité dans les graphes du web. 

		\subsection{Principe de fonctionnement :}
		
	Le moteur $k^2$-GraCE a été conçu pour permettre la compression de graphes statiques ou dynamiques et orientés ou non orientés. Il se base sur les travaux de Brisaboa et al. \citep{brisaboa2009k}. Il offre la possibilité de construire le graphe compressé à partir de la matrice d'adjacence, de la liste d'adjacence ou du graphe directement. Il permet aussi dans le cas des graphes dynamiques de réduire davantage la taille de l'arbre en le construisant non pas à partir de la matrice d'adjacence initiale mais en calculant une matrice de différence entre les instants $t_i$. 
	
	
$k^2$-GraCE est un moteur de compression sans perte de données. En effet, il construit en sortie un arbre $k^2$-tree incluant toute information présente dans le graphe initial. Cette information est représentée sous forme de deux chaines binaires. Le processus de compression d'un graphe de données par le moteur $k^2$-GraCE passe par les étapes suivantes :
\begin{enumerate}
\item Lecture et structuration du graphe de données en entrée 
\item Pré-traitement : cette étape est optionnelle, elle ne figure pas dans l'algorithme de base. 
\item Construction récursive de l'arbre k2-tree à partir de la matrice d'adjacence (ou de la liste d'adjacence ou du graphe directement) et la concaténation des différents niveaux de l'arbre dans une première chaine T, à l'exception du dernier niveau qui sera stocké dans une deuxième chaine L.

\item Écriture du graphe compressé sur le fichier de sortie.
\end{enumerate}

Nous illustrons ces phases par la figure \ref{k2grace} qui donne une vue globale sur le principe de fonctionnement de ce moteur.


\begin{figure}[H]
\includegraphics[scale=0.48]{./ressources/image/ograce.jpg}
\caption[Principe de fonctionnement du moteur $k^2$-GraCE]{Principe de fonctionnement du moteur $k^2$-GraCE.}
			\label{k2grace}
\end{figure}
Après avoir expliquer de manière générale le principe de fonctionnement du moteur $k^2$-GraCE, nous présenterons dans ce qui suit les détails des deux phases : la phase de pré-traitement et la phase de compression (construction de l'arbre). Nous allons tout d'abords commencer par présenter les notations et opérations de base qui seront utilisées par la suite. Nous enchainerons par les différents algorithmes de construction selon le type de graphe en entrée.
		
		\subsection{Paramètre et notations :}
				
		\begin{table}[H]
		\centering
		\begin{tabular}{|c|L{12cm}|}
		\hline Paramètre & Signification \\ \hline\hline 
		$G$ & Graphe de données \\ \hline
		$M$ & Matrice d'adjacence du graphe G\\ \hline
		$List$ & Liste d'adjacence du graphe G\\ \hline
		$A$ & L'arbre $k^2$-tree \\\hline
		$T$ & Le nombre d'instants dans lesquels le graphe a été capturé \\\hline
		$h$ & La hauteur de l'arbre $k^2$-tree \\ \hline
		$N$ & Nombre de nœuds dans le graphe \\ \hline
		$k$ & Paramètre déterminant le nombre de fils dans l'arbre $k^2$-tree\\ \hline
		: & opérateur de concaténation \\ \hline
		rank($T,i$) &  Fonction calculant le nombre de 1 existant dans le tableau binaire $T$ dans l'intervalle des indices [$1,i$] \\ \hline
		\end{tabular}
		\caption{Tableau des notations et paramètres du moteur $k^2$-GraCE.}	
		\label{notk2grace}		
	\end{table}
	
		\subsection{Conception Modulaire:}
		
		Dans cette partie, nous détaillerons chaque phase du moteur $k^2$-GraCE. Nous commencerons par présenter les différentes techniques de pré-traitement 
		que nous voulons utiliser avec notre moteur. Nous expliquerons par la suite le processus de compression pour chaque type de graphe supporté par le moteur $k^2$-GraCE. %et nous allons aussi fournir les différents algorithmes d'extraction de voisins en Annexe \ref{k2_annexe}. 
		
			\subsubsection{Pré-traitement du graphe de données:}
Durant cette première phase, le moteur $k^2$-GraCE utilise des stratégies qui permettrons d'aboutir à une meilleur compression. Il offre une alternative pour chaque type de graphe qu'il supporte. 		
			
			
			Dans le cas des graphes statiques orientés, $k^2$-GraCE offre la possibilité de ré-ordonnoncer les nœuds du graphe de données G.
			% Nous expliquerons  dans ce qui suit les différents algorithmes de ré-ordonnancement qui peuvent être utiliser dans notre moteur. 
			Comme notre travail est une suite d'un travail d'étudiants de l'année précédente \citep{master2017}, cette phase a été déjà conçue et implémentée. Nous rappellerons uniquement dans cette section le principe de base de chaque méthode. 
			
			\begin{itemize}[label=$\bullet$]
\item\textbf{Ordre Lexicographique :} Les nœuds sont ordonnés selon leurs listes de successeurs. Les listes de successeurs seront donc triées selon un ordre croissant des identifiants et par la suite ordonnées.

	
\item\textbf{Ordre Gray :} Les nœuds sont permutés de telle sorte que deux nœuds dont l'ordre est successif diffèrent dans au plus un voisin. 
\item\textbf{Ordre \gls{dfs} :} Les nœuds sont ordonnés selon leurs positions dans le parcours en largeur (\gls{dfs}) du graphe.  
\item\textbf{Ordre \gls{bfs} :} Les nœuds sont ordonnés selon leurs positions dans le parcours en profondeur (\gls{bfs}) du graphe. 
\item\textbf{Ordre Aléatoire :} Des permutations aléatoires des nœuds sont établies.
			
			\end{itemize}
		
	Le deuxième type de graphe supporté par le moteur $k^2$-GraCE correspond aux graphes statiques non orientés. Dans ce cas, nous obtenons une matrice d'adjacence symétrique. De ce fait, nous proposons de ne considérer que la partie triangulaire supérieure pour enlever la redondance portée par la symétrie. L'arbre construit ainsi offre toujours la possibilité d'extraire le voisinage d'un nœud sans avoir recours à une décompression. En effet, extraire les voisins d'un nœud dans le graphe initial revient à extraire les voisins directs et inverses dans la nouvelle matrice construite en utilisant les mêmes algorithmes de l'annexe \ref{k2_annexe}.
	 Si nous prenons l'exemple du nœud 2 dans la figure \ref{k2_non}, ses voisins sont représentés par les 1 de la deuxième ligne ou de la deuxième colonne dans la matrice d'origine (matrice gauche) et par l'union des cellules ayant un 1 de la deuxième ligne et de la deuxième colonne dans la matrice droite ce qui nous donne : $v(2) = \{1, 2, 5,6\}$.
	
\begin{figure}[H]
\centering
	\includegraphics[scale=0.4]{./ressources/image/k2_non.png}
	\caption[Exemple d'arbre $k^2$-tree (k=2) pour un graphe non orienté.]{Exemple d'arbre $k^2$-tree (k=2) pour un graphe non orienté.}
	\label{k2_non}
\end{figure}	


	
	$k^2$-GraCE supporte aussi les graphes dynamiques. Dans le cas de ce type de graphe, il offre la possibilité de calculer une matrice différence à partir de la matrice initiale. Le but de cette fonctionnalité est de maximiser les zones nulles dans la matrice afin de réduire la taille de l'arbre. À \textit{t}=0, nous gardons la même matrice bidimensionnelle du graphe initial. Pour les instants restants (\textit{t} > 0), nous comparons $M_{pq}$ à l'instant t avec $M_{pq}$ à l'instant \textit{t-1}, si égalité alors la nouvelle matrice contiendra un 0 dans la cellule \textit{pq} à l'instant \textit{t} sinon elle contiendra un 1. La nouvelle matrice d'adjacence contiendra ainsi uniquement les changements qui occurrent entre les instants. La figure \ref{mat_diff} montre une matrice d'adjacence d'un graphe dynamique capturée dans trois instants différents avec sa matrice de différence et la représentation $k^2$-tree dans les deux cas.

\begin{figure}[H]
\centering
	\includegraphics[scale=0.48]{./ressources/image/dynk2diff.png}
	\caption[Exemple d'arbre $k^2$-tree (k=2) pour la matrice de différence]{Exemple d'arbre $k^2$-tree (k=2) pour la matrice de différence.}
	\label{mat_diff}
\end{figure}

L'inconvénient de cette fonctionnalité réside dans le fait qu'une reconstruction de la matrice initiale est nécessaire dans le cas d'interrogation du graphe. Un autre inconvénient de cette technique est qu'elle dégrade les performances dans le cas où les différentes captures ne possèdent pas des arêtes en commun. Dans le cas de disparition de liens par exemple nous obtiendrons des zéros (0) qui vont être remplacés par des uns (1) engendrant ainsi une matrice plus dense. Le gain apporté par cette technique est fortement dépendant des caractéristiques du graphe. 
Nous fournissons ci-après l'algorithme de construction de la matrice de différence :\\

	\begin{algorithm}[H]
					
					\caption{ConstructDiffMatrice}
					\label{alg:diffMat}
					\textbf{Entrée :}
						\begin{itemize}[label=$\bullet$]
							\item M[][][] : la matrice d'adjacence
						\end{itemize}
					\textbf{Sortie :} La matrice de Différence\\							\noindent\rule{\textwidth}{1pt}
						
						
				\begin{algorithmic} [1]
					\STATE MatriceDiff[][][]
					\STATE MatriceDiff[1,:,:] = M[1,:,:]
					\FOR{$i = 2 ... T $} 
						\FOR{$j = 1 ... N $} 
							\FOR{$k = 1 ... N $} 
								\IF {M[i][j][k] = M[i-1][j][k]}
									\STATE MatriceDiff[i][j][k] = 0
								\ELSE
									\STATE MatriceDiff[i][j][k] = 1
								\ENDIF
							\ENDFOR
							
						\ENDFOR
					\ENDFOR
				
					\RETURN MatriceDiff
				\end{algorithmic}
			\end{algorithm}


Nous notons que l'utilisation de ce module dans le processus de construction de l'arbre $k^2$-tree n'est pas obligatoire. Cette phase ne figure pas dans l'algorithme de base. Nous voulons, à travers son intégration dans le moteur \gls{$k^2$-GraCE}, rassembler davantage les nœuds ayant des voisins communs et donc les zones homogènes dans la matrice d'adjacence (zones plaines de 0 ou zones plaines de 1) ou augmenter le nombre de cellules nulles dans la matrice d'adjacence.
		
			\subsubsection{Construction de l'arbre $k^2$-tree}
			
			$k^2$-tree est une représentation compacte de la matrice d'adjacence qui exploite ses propriétés de similarité et de localité. Elle était destinée au départ pour les graphes du web et généralisée par la suite pour différents cas. La représentation est conçue pour compresser les grandes zones nulles de la matrice d'adjacence en les représentant avec un nombre réduit de bits. Plusieurs alternatives existent pour construire l'arbre $k^2$-tree: l'utilisation de la matrice d'adjacence, l'utilisation de la liste d'adjacence ou l'utilisation du graphe directement. Dans tous les cas, nous obtenons une représentation sous forme d'un arbre ayant une hauteur h= $log_k(N)$ où chaque nœud possède $k^2$ fils. 
			  Pour représenter l'arbre de manière concise, deux structures seront utilisées :
			\begin{itemize}
			\item \textbf{T }: Un tableau qui stocke tous les bits du $k^2$-tree sauf ceux du dernier niveau. Les bits de l'arbre $k^2$-tree sont placés après une traversée horizontale de l'arbre. $k^2$-GraCE représente d'abord les $k^2$ valeurs binaires des fils du nœud racine, puis les valeurs du deuxième niveau, ...etc.
			
			\item  \textbf{L} : Un tableau stockant le dernier niveau de l'arbre. Ainsi, il représente la valeur des (ou de certaines) cellules de la matrice d'adjacence du graphe initial.
			\end{itemize}
			
			L'algorithme \ref{alg:k2_tree} résume les différentes étapes de construction de l'arbre $k^2$-tree dans le cas de la construction à partir de la liste d'adjacence. Nous dotons pour cela la liste d'adjacence de \textit{n} curseurs, un par ligne, de sorte que chaque fois que nous devons accéder à $M_{pq}$, nous comparons le curseur actuel de la ligne $p$ à la valeur \textit{q}. S'ils sont égaux, alors on aura $M_{pq} = 1$ et nous devons avancer le curseur vers le nœud suivant de la liste de la ligne \textit{p}. Sinon, nous saurons que $M_{pq} = 0$. 
			
			Nous supposons que la liste d'adjacence $List$, le nombre de fils $k$ ainsi que l'arbre $k^2$-tree $A$ sont des variables globales. Pour construire l'arbre à partir de la racine, elle sera invoquée comme suit :  ConstructK2Tree(N,1,0,0). Après avoir construit l'arbre $A$ sous forme d'un tableau de niveau, nous procèderons à la construction des deux structures selon les deux formules suivantes :
			\begin{itemize}[label=$\bullet$]
			 	\item T = $A_1: A_2:. . . :A_{h-1}$
			 	\item L = $A_h$
			\end{itemize}	

Des versions itératives de l'algorithme peuvent être établies. Cependant, elles dégradent les performances car elles nécessitent soit l'utilisation de structures supplémentaires ou plus d'accès mémoire. Nous avons privilégié la version récursive car elle permet de construire l'arbre $k^2$-tree en un seul parcours de la liste d'adjacence $List$.\\

					\begin{algorithm}[H]
					\label{alg:k2_tree}
					\caption{ConstructK2Tree}
					\textbf{Entrée :}
						\begin{itemize}[label=$\bullet$]
							\item n : la taille de la sous-matrice
							\item l : le niveau de l'arbre
							\item p : l'indice ligne de début de la sous-matrice
							\item q : l'indice colonne de début de la sous-matrice
						\end{itemize}
					\textbf{Sortie :} La valeur du nœud de la sous-matrice\\							\noindent\rule{\textwidth}{1pt}
						
						
				\begin{algorithmic} [1]
					\STATE C = $ \emptyset$
					\FOR{$i = 1 ... k $} 
						\FOR{$i = 1 ... k $} 
							\IF {$l = log_k(N)$} 
								\STATE // Condition selon le type de représentation en entrée 
								\STATE // Matrice d'adjacence : M[p+i,q+j] = 1 
								\STATE // Graphe : $e_{p+i,q+j} \in E$
								\IF { $List$[p+i].courrant() = q+j }
								
									\STATE C = C : 1
									\STATE $List$[p+i].avancer()
								\ELSE
									\STATE C = C : 0
								\ENDIF
							\ELSE
								\STATE  C = C : ConstructK2Tree ( $n/k,l+1,p+i*(n/k), q+j*(n/k)$)
							\ENDIF
						\ENDFOR
					\ENDFOR
					\IF {$C\ est\ un\ vecteur\ nul$} 
						\RETURN 0
					\ENDIF
					\STATE A[l] = A[l] : C
					\RETURN 1
				\end{algorithmic}
			\end{algorithm}
	
	
		Une fois construites, les deux structures (T et L) permettent d'extraire les voisins directs et inverses d'un nœud directement sans décompression. Nous fournissons dans l'annexe \ref{k2_annexe} les détails de ces  algorithmes d'extraction de voisinage.		
			
	

	Dans le cas des graphes dynamiques. Ces graphes sont représentés par un ensemble de graphes statiques chacun capturé à un instant $t_i$. De ce fait, l'algorithme de construction peut être facilement adapté avec chaque nœud dans l'arbre contenant, cette fois-ci, un vecteur de bits chacun faisant référence à un instant $t_i$. Nous fournissons ci-après (algorithme \ref{alg:dynk2_tree}) l'algorithme de construction de l'arbre $k^2$-tree à partir de la matrice d'adjacence tridimensionnelle.\\
	


	
					\begin{algorithm}[H]
					\label{alg:dynk2_tree}
					\caption{DynK2Tree}
					\textbf{Entrée :}
						\begin{itemize}[label=$\bullet$]
							\item n : la taille de la sous-matrice
							\item l : le niveau de l'arbre
							\item p : l'indice ligne de début de la sous-matrice
							\item q : l'indice colonne de début de la sous-matrice
						\end{itemize}
					\textbf{Sortie :} La valeur du nœud de la sous-matrice\\							\noindent\rule{\textwidth}{1pt}
						
						
				\begin{algorithmic} [1]
					\STATE C = $ \emptyset$
					\STATE Creturn  = $ \emptyset$
					\FOR{$i = 1 ... k $} 
						\FOR{$j = 1 ... k $} 
							\IF {$l = log_k(N)$}
								\FOR{$m = 1 ... T $}
									\STATE C[m] = C[m] : M [p+i][q+j][m]
								\ENDFOR
							\ELSE
								\STATE Ctmp =$\emptyset$
								\STATE  Ctmp = DynK2Tree ( $n/k,l+1,p+i*(n/k), q+j*(n/k)$)
								\FOR{$m = 1 ... taille(Ctmp) $}
									\STATE C[m] = C[m] : Ctmp[m]
									\STATE Creturn [m] = Creturn [m] ou Ctmp [m]
								\ENDFOR
							\ENDIF
						\ENDFOR
					\ENDFOR
					\IF {$C\ est\ un\ vecteur\ nul$} 
						\RETURN $0^{|T|}$ // retourner un vecteur nul de taille T.
					\ENDIF
					
					
					
					\FOR{$i = 1 ... k*k $} 
						\FOR{$j = 1 ... T $}
							\IF{ $C[i]$ n'est pas un vecteur nul}
								\STATE A[l] = A[l] : C [i][j]
							\ENDIF
						\ENDFOR
					\ENDFOR
	
					 \RETURN Creturn
					
				\end{algorithmic}
			\end{algorithm}
			
			
	
	
	
	\section{P-GraCE :}
	
	Notre deuxième moteur \gls{P-GraCE} est un moteur de compression par extraction de motifs. Il englobe un ensemble de méthodes basées sur quatre  approches de compression différentes mais qui partagent toutes le même schéma global de compression. Le moteur regroupe les méthodes suivantes : la méthode Subdue \citep{ketkar2005subdue} qui est basée sur l'approche beam search et qui supporte les graphes statiques non orientés étiquetés , les deux méthodes \gls{ConDenSe} \citep{liu2018reducing} et \gls{vog} \citep{koutra2015summarizing} qui sont toutes les deux basées sur les méthodes de clustering et appliquées sur les graphes statiques non orientés, La méthode \gls{dsm} \citep{hernandez2014compressed} basée sur le minhashing et qui supporte les graphes statiques orientés, et enfin la méthode \gls{gcupmt} \citep{shah2018graph} basée sur l'extraction des motifs à partir de la matrice d'adjacence et qui s'adapte aux graphes statiques orientés et non orientés.  Nous présenterons dans cette partie, en détails, le principe de fonctionnement des différentes approches et les différents phases qui les constituent.
	
		\subsection{Principe de fonctionnement :}
		
		Les méthodes de compression par extraction de motifs sont des méthodes qui essayent de représenter le graphe de données à travers ses motifs, autrement dit ses sous-graphes portant les informations les plus importantes. 
		
		P-GraCE est un moteur de compression comportant plusieurs méthodes qui peuvent être avec ou sans perte de données. 
		En effet, le modèle produit en sortie (résultat de la compression) est parfois accompagné avec une matrice d'erreur qui sera représentée dans ce cas avec une structure d'arbre $k^2$-tree. Le processus de compression d'un graphe de données par le moteur P-GraCE passe par les étapes suivantes :
		
\begin{enumerate}

\item Lecture et structuration du graphe de données en entrée. 

\item Extraction et évaluation des motifs : Durant cette phase, une détection des motifs les plus denses ou les plus fréquents est réalisée. Leur évaluation dans cette phase permet de déterminer les structures (motifs) susceptibles de donner une meilleur compression.

\item Traitement des motifs: Ce module permet d'encoder ou d'agréger, dans certains cas, les motifs déjà découverts dans le but de minimiser davantage la taille du graphe en sortie. Dans d'autres cas, le module retourne une liste de structures sélectionnées parmi les motifs précédemment identifiés en utilisant des heuristiques dans le but de ne garder que les motifs importants du graphe. 
%Nous notons que l'utilisation de ce module n'est pas présente dans toutes les méthodes de ce moteur mais dans la plupart 

\item Écriture du graphe compressé sur le fichier de sortie.
\end{enumerate}

La figure \ref{P_grace} permet d'illustrer le principe de fonctionnement globale du moteur \gls{P-GraCE}


\begin{figure}[H]
	\includegraphics[scale=0.48]{./ressources/image/pgrace.jpg}
	\caption[Vue globale sur le fonctionnement du moteur \gls{P-GraCE}.]{Vue globale sur le fonctionnement du moteur P-GraCE.}
	\label{P_grace}
\end{figure}

Nous présenterons dans ce qui suit les trois phases de chaque approche incluse  dans le moteur P-GraCE. Nous précèderons  cela par expliquer les différents paramètres et notations que nous avons adoptés durant la conception de notre deuxième moteur.
		
		\subsection{Paramètre et notations :}
		
			\begin{table}[H]
		\centering
		\begin{tabular}{|c|L{12cm}|}
		\hline Paramètre & Signification \\ \hline\hline 
		$G$ & Graphe de données \\ \hline
		$V$ & L'ensemble des nœuds de G\\ \hline
		$E$ & L'ensemble des arêtes de G \\ \hline
		$L$ & L'ensemble des étiquettes de G \\ \hline
		$A$ & Matrice d'adjacence du graphe G\\ \hline
		$D$ & Matrice des degrés du graphe G\\ \hline
		$M$ & Le modèle produit par la compression\\ \hline
		$h$ & Heuristique d'évaluation \\ \hline
		$N$ & Nombre de nœuds dans le graphe \\ \hline
		$k$ & Paramètre déterminant le nombre de fils à considérer dans le beam-search\\ \hline
		$s$ & Structure extraite à partir du graphe G\\ \hline
		$g$ & Sous-graphe complet englobant la structure s\\ \hline
		\end{tabular}
		\caption{Tableau des notations et paramètres du moteur P-GraCE.}	
		\label{notk2grace}		
	\end{table}
		
		\subsection{Conception modulaire :}
		
		Durant cette section, nous allons présenter les différentes approches qui sont offertes par le moteur P-GracE. Nous commencerons par expliquer les méthodes d'extraction de motifs utilisées dans chacune. Nous enchainerons avec les techniques d'évaluation employées par ces méthodes, pour finir par expliquer comment ces motifs seront traités et utilisés pour compresser le graphe. 	
		
		
		\subsubsection{Extraction des motifs :}

La phase d'extraction de motifs est une phase très importante dans le processus de compression. Elle permet de trouver les composantes les plus denses qui représentent en général l'information utile dans un graphe de données. Plusieurs techniques existent pour réaliser cette tâche. Elles diffèrent dans la qualité des sous-structures découvertes selon le domaine d'application et le type de graphe en entrée. Nous présenterons ci-dessous les quatre approches offertes par le moteur P-GraCE.
		
\begin{enumerate}

\item \textbf{Beam search:}\\
Le beam search est une méthode de recherche locale gloutonne. C'est une version améliorée de l'algorithme de recherche en largeur \gls{bfs}. Elle permet de n'explorer que les $k$ meilleurs fils dans chaque niveau à travers des heuristiques d'évaluation. Comme nous l'avons déjà mentionné, cette technique est utilisée dans la phase d'extraction de motifs de la méthode Subdue.

Dans le cas d'extraction de motifs dans un graphe, le beam search commence par considérer que chaque nœud du graphe est un motif. Il utilise pour cela un arbre de recherche où ses nœuds sont des sous-structures. À chaque itération les motifs sont étendus par une arête et un nœud donnant ainsi un ensemble de sous-structures. Par la suite, les $k$ meilleurs sous-structures sont choisies. Les fils restants sont donc élagués. %Le processus continues jusqu'à ce que
Cette alternative sera employée pour le cas des graphes étiquetés. Nous fournissons ci-après l'algorithme du beam search que nous avons utilisé. 


\begin{algorithm}[H]
					\label{alg:beamSearch}
					\caption{Beam-Search}
					\textbf{Entrée :}
						\begin{itemize}[label=$\bullet$]
							\item G : le graphe de donnée
							\item k : le nombre de fils à considérer
							\item limit : limite de la profondeur de l'arbre
						\end{itemize}
					\textbf{Sortie :} retourne la meilleur sous-structure\\							\noindent\rule{\textwidth}{1pt}
						
						
				\begin{algorithmic} [1]
					\STATE C = $\{v\ |\ v$ est un nœud ayant une unique étiquette dans  $G\}$
					\STATE $meilleurStruct$ = la première sous-structure de C
					\REPEAT
					\STATE nouvelC= $\emptyset$
					\FOR{ chaque S dans C} 
						\STATE nouvelStruct = Etendre(S)
						\STATE Evaluer(nouvelStruct)
						\STATE nouvelC = nouvelC $\cup$ \{ les k meilleur sous-structures de nouvelStruct \}
					\ENDFOR
					\STATE limit = limit -1
					\IF {$h$( meilleur sous-structure de C) >= $h$($meilleurStruct$)  }
					
					\STATE $meilleurStruct$  = meilleur sous-structure de C
					\ENDIF
					\STATE C = nouvelC
					\UNTIL{$C = \emptyset $ ou $limit \leq 0$}
					
				\end{algorithmic}
			\end{algorithm}
			
Afin de mieux illustrer le fonctionnement de cet algorithme, nous proposons l'exemple du graphe de la figure \ref{beam}. Nous considérons dans cet exemple qu'un sommet est représenté sur 8 bits, un lien est représenté sur 8 bits et que chaque pointeur est représenté sur 4 bits.


\begin{figure}[H]
	\centering
	
	\includegraphics[scale=0.5]{ressources/image/beam_search.png}
	\caption{Exemple de Graphe Étiqueté}
	\label{beam}
 \end{figure}
 
 Au départ chaque nœud est considéré comme une sous-structure, nous obtenons donc quartes sous structures:  A, B, C et X. Par la suite, chacune des sous structures  est étendues par un sommet et une arête tout en estimant le gain obtenu par chaque extension. Nous obtenons donc encore quatre sous structures : A-B, A-C, B-C et X-C. Les trois premières sous-structures donnent le même gain de 24 bits. Tant dis que la quatrième donne une configuration non permise à cause des chevauchements entre ses instances qui possèdent le nœud x  en commun.  La dernière étape donne ainsi le motif A-B-C apportant un gain de 64 bits et qui représente la meilleur sous-structure.  
 
 \begin{figure}[H]
	\centering
	
	\includegraphics[scale=0.5]{ressources/image/beam_tree.png}
	\caption{Arbre de recherche (k= $ {\infty} $ , limit = $ {\infty} $)}
	\label{beam_tree}
 \end{figure}
 
%Les nœuds du meilleur motif seront agrégés en un seul nœud. La figure \ref{beam_res} donne le résultat finale.  
 
 % \begin{figure}[H]
%	\centering
%	
%	\includegraphics[scale=0.5]{ressources/image/beam_result.png}
%	\caption{Résultat de l'exécution de l'algorithme du beam-search}
%	\label{beam_res}
% \end{figure}


\item \textbf{Méthodes de clustering :}

%Plusieurs méthodes de clustering existent dans la littérature. Durant la phase d'extraction de motifs des deux méthodes CanDense et VoG,le moteur P-GraCE utilise un ensemble de techniques de clustering pour décomposer le graphe de données en entrée en plusieurs sous-graphes. Nous les détaillons dans ce qui suit. 
Durant la phase d'extraction de motifs des deux méthodes \gls{ConDenSe} et \gls{vog}, le moteur P-GraCE utilise un ensemble de techniques de clustering pour décomposer le graphe de données en entrée en plusieurs sous-graphes. Une large gamme de méthodes de détection de communautés existe dans la littérature, le moteur P-Grace utilise trois d'entre elles que nous détaillons dans ce qui suit. 

\textbf{\textit{SlashBurn}} : Cette technique part de l'observation  que les graphes du monde réel sont facilement décomposables en supprimant les nœuds de haute centralité qui sont définies comme les nœuds ayant un degré maximale dans le graphe G.  
 
À chaque itération le graphe est décomposé en un nœud central appelé hub, un
\newacronym{gcc}{CCG}{Composant Connecté Géant} \gls{gcc} définit comme étant la composante connexe ayant le degré maximal et les composantes connexes restantes que nous appelons composantes non géantes . Le hub obtient le plus petit identifiant, les nœuds des composantes non géantes reçoivent les identifiants les plus élevés  dans l'ordre décroissant de la taille de la composante connectée à laquelle ils appartiennent, et le nouveau \gls{gcc} prend les identifiants restants. Le même processus s'applique aux nœuds du nouveau \gls{gcc}, de manière récursive.
A la fin de l'algorithme, chaque hub et l'ensemble de ses voisins seront considérés comme une structure. Ainsi que chaque composante connexe non connectée.

Nous illustrons le principe de fonctionnement de cette méthode de clustering sur le graphe de la figure \ref{Img:slashb}. Le nœud hub (8) obtient le plus petit identifiant (1), les nœuds des composantes  non géantes reçoivent les identifiants les plus élevés (9-16), et le \gls{gcc} prend les identifiants restants (2-8). La prochaine itération considère le nouveau \gls{gcc}. Nous fournissons l'algorithme détaillé en annexe \ref{alg:SlashBurn}.

\begin{figure}[H]
	\centering
	
	\includegraphics[scale=0.25]{ressources/image/slashburn.png}
	\caption{Exemple d'application de l'algorithme SlashBurn}
	\label{Img:slashb}
 \end{figure}

\textbf{\textit{K-Cores}} : Cette technique se base sur le principe de dégénérescence \footnote{: La dégénérescence d’un graphe G est le plus petit nombre k de
 telle sorte que chaque sous-graphe $S \in G$ contient un sommet de degré au plus k}. Soit G un graphe non orienté, nous notons par $\Delta$(G) le degré maximal des nœuds de G. Un k-core de G est un sous graphe H de taille maximale tel que $\Delta(H) \le k$ avec k entier positif.\\
Pour décomposer le graphe, la méthode passe par quatre étapes. D'abord, le degré k de chaque nœud du graphe est calculé. Ensuite, pour chaque degré k allant du plus grand au plus petit le graphe est décomposé en supprimant tous les nœuds dont le degré est inférieure à k, l'opération s'arrête si la décomposition donne un ensemble non vide et le k est choisit comme $k_{max}$ sinon elle se termine quand $k_{max}$=1. Après la décomposition, chaque composant est identifié comme étant une structure. Enfin, les arêtes entre les structures précédemment identifiées sont supprimées. L'algorithme de la méthode est donné en Annexe (\ref{alg:KCBC})\\


\textbf{\textit{Spectral}} : Cette méthode se fonde sur l'utilisation des k-means dans un nouveau espace, celui des k premiers vecteurs propres de la matrice dite Laplacienne du graphe. La matrice Laplacienne peut être définie de la façon suivante : L = D - A où D représente la matrice des degrés, e.i ${d}_{i} := \sum_{(v_i,v_j) \in E} e(v_i,v_j)$ et A la matrice d'adjacence du graphe. Quand le graphe est composé de k composantes connexes, on peut les
retrouver à partir des k premiers vecteurs propres de la matrice
laplacienne. Il suffit de choisir le nombre k des sous graphes souhaités (k = $\sqrt{\frac{\textit{N}}{2}}$ pour notre part), puis de représenter chaque sommet dans un espace à k dimensions où les coordonnées correspondent
aux valeurs des k premiers vecteurs propres. Dans cet espace, l'ensemble des sommets fortement
connectées entre eux seront très proches (voire similaire si l’ensemble est une composante connexe) et les ensembles faiblement connectés seront très éloignés. Un simple
k-means suffit alors à discriminer les différents clusters. L'algorithme est le suivant : 

\begin{algorithm}[H]
					\label{alg:spectral}
					\caption{Spectral}
					\textbf{Entrée :}
						\begin{itemize}[label=$\bullet$]
							\item A : matrice d'adjacence du graphe
							\item k : nombre de clusters 
							
						\end{itemize}
					\textbf{Sortie :} ensemble de clusters\\							\noindent\rule{\textwidth}{1pt}
						
						
				\begin{algorithmic} [1]
				\STATE Calculer D la matrice des degrés de G.				 
				 \STATE Calculer L la matrice Laplacienne de G : L = D - A
				 \STATE  Calculer les k premiers vecteurs propres $u_1$, . . . , $u_k$ de L.
				 \STATE Former la matrice U de taille $n \times k$ dont les colonnes
sont $u_1$, . . . , $u_k$
\STATE Créer des clusters $C_1$, . . . , $C_k$ sur les n lignes de U par
k-means
				\end{algorithmic}
			\end{algorithm}

Notons que la méthode \gls{vog} s'appuie sur SlashBurn pour l'extraction de motifs, contrairement à \gls{ConDenSe} qui emploie l'une des trois méthodes ou toutes les méthodes à la fois dans cette phase d'extraction.

\item \textbf{Le MinHash:}

Dans cette alternative, nous allons partitionner le graphe en des motifs denses dont les nœuds sont fortement connectés. Nous utiliserons pour cela une approximation de \textit{la similarité de Jaccard} qui est une métrique permettant de mesurer la similarité entre deux ensembles $S_1$ et $S_2$ (voir formule \ref{eq:Jacc}). Nous rappelons que le minHashing est appliqué dans le processus d'extraction de motifs de la méthode \gls{dsm}.

\begin{equation} \label{eq:Jacc}
SIM(S_1,S_2)=\frac{|S_1 \cap S_2|}{|S_1 \cup S_2|}
\end{equation}


L'objectif de cette méthode est de remplacer les listes d'adjacence des nœuds par des représentations beaucoup plus petites appelées « signatures ». La propriété importante de ces signatures est que leur comparaison permet d'estimer la similarité de Jaccard des listes d'adjacence sans avoir recours à les comparer deux à deux. 

Avant d'expliquer comment il est possible de construire de petites signatures à partir des listes d'adjacence, il est utile de les visualiser en tant que matrice caractéristique. Les colonnes de cette matrice correspondent aux listes d'adjacence et les lignes correspondent aux nœuds. Nous rappelons que la matrice caractéristique est peu susceptible d'être la façon dont les données sont stockées, mais elle est utile pour visualiser les données (voir figure \ref{jacc}). 


Dans un premier temps, k-permutations aléatoires des nœuds devront être choisies. L'utilisation des k-permutations se base sur le fait que :
%% Ajouter demonstration en Annexe ou donner la source 
\begin{equation} \label{eq:prob}
P(\pi_i(S_1) = \pi_j(S_2)) = \frac{|S_1 \cap S_2|}{|S_1 \cup S_2|} = SIM(S_1,S_2)
\end{equation}

 Nous construisons la matrice de signature en considérant chaque ligne dans leur ordre donné. Soit $SIG (i, c)$ l'élément de la matrice de signature pour la $i^{ème}$ fonction de hachage et la colonne c. SIG (i, c) est initialisée à $\infty$ pour tout i et c. Nous traitons une ligne r en procédant comme suit:
\begin{enumerate}
\item nous calculons $h_1 (r), h_2 (r), ..., h_k (r)$.
\item Pour chaque colonne, nous procédons comme suit: 
	\begin{itemize}
		\item  Si c = 0 dans la ligne r, rien à faire.
		\item  Cependant, si c = 1 dans la ligne r, alors pour chaque i = 1,2, ..., k  \\$SIG (i, c)$ = min( $SIG (i, c)$ , $h_i(r)$ ).
	\end{itemize}
\end{enumerate}




Une fois les signatures sont construites, les nœuds ayant les mêmes valeurs seront regroupés. Nous obtiendrons ainsi en sortie la liste des motifs contenant les nœuds ayant un voisinage similaire dans le graphe de données. Nous illustrons le principe de fonctionnement de cette stratégie sur un graphe G dans la figure \ref{jacc}. Le tableau gauche de la figure \ref{jacc} montre une matrice caractéristique des listes d'adjacence des différents nœuds du graphe G ainsi que deux permutations aléatoires $h_1$, $h_2$. Tant dis que le tableau à droite de la même figure montre les étapes de calcul des signatures en utilisant ces deux fonctions. La matrice finale des signatures montre bien que les nœuds 1 et 4 sont les plus similaires ce qui est justifié par leurs listes d'adjacence qui ne diffèrent que dans un seul élément.  

\begin{figure}[H]
\centering
	\includegraphics[scale=0.48]{./ressources/image/jacc.png}
	\caption[Exemple de calcul de la matrice des signatures.]{Exemple de calcul de la matrice des signatures.}
	\label{jacc}
\end{figure}

Après l'étape de clustering,  une arborescence est ensuite construite pour chaque ensemble de sommets ayant les même signatures et qui permettra d'extraire les sous-structures (motifs) denses du graphe à travers un parcours de la racine vers les feuilles. 

\item \textbf{Extraction de Motifs de la matrice d'adjacence:}

\gls{gcupmt} qui est la dernière méthode offerte par le moteur se base sur l'exploitation des blocs les plus fréquents dans la matrice d'adjacence.  Cette méthode est destinée aux graphes ayant une matrice d'adjacence contenant de larges zones nulles. L'ensemble des motifs à découvrir est prédéfinies au départ et consiste en trois types de motifs qui sont paramétrés par la taille du motif :
%La dernière méthode d'extraction de motifs offerte par le moteur P-GraCE se base sur les blocs les plus fréquents dans la matrice d'adjacence.%

	\begin{enumerate}[label=(\alph*)]
		\item \textbf{Type 01 :} Ce premier ensemble de motifs consiste en les vecteurs ayant uniquement deux '1', le premier dans le bit de poids fort et un autre dans l'une des position restantes, et le vecteur nul. Pour une taille de motif de $2^n$ bits, nous obtenons un ensemble de taille $2^n$.
		
		
		
		\item \textbf{Type 02 :} Le deuxième ensemble de motifs consiste en les vecteurs ayant uniquement un seul '1'. La taille de cet ensemble est de $2^n$ motifs pour des motifs de taille $2^n$ bits.
		\item \textbf{Type 03 :}  Ce dernier ensemble de motifs consiste en l'union des deux ensembles précédents. Dans le cas de cet ensemble, nous obtenons $2^{n+1}$ motifs pour une taille de motifs de $2^n$.
	\end{enumerate}	

Chaque ligne de la matrice d'adjacence est donc divisée en plusieurs blocs ayant la même taille que les motifs. Ces blocs seront comparés avec les motifs selon le type choisi et dans le cas de correspondance ils seront remplacés par l'identifiant du motif (0...n-1) sous forme binaire qui est de taille n pour des motifs de taille $2^n$.


	
\end{enumerate}
		
		\subsubsection{Évaluation des motifs :}
		
		 Dans cette deuxième phase, P-GraCE cherche à obtenir la meilleur compression en filtrant les sous-structures et en ne gardant que celles qui offrent un bon \gls{mdl}. 
		 
		 \begin{enumerate}
		% Comme nous l'avons déjà précisé P-GraCE utilise le beam-search pour le cas des graphes  étiquetés.
		 \item Comme nous l'avons déjà précisé P-GraCE utilise le beam-search pour compresser les graphes étiquetés dans la méthode Subdue. Il est fondamentalement guidé par le principe \gls{mdl}. L'évaluation heuristique effectuée suppose que la meilleure sous-structure est celle qui minimise le \gls{mdl} du graphe en entrée lorsqu'il est compressé par cette sous-structure (S). Notons la longueur de description de S par \textit{DL(S)}, la longueur de description du graphe d'entrée G  par \textit{DL(G)} et la longueur de description du graphe après compression par \textit{DL(G|S)}. L'heuristique est alors rien d'autre que le ratio de compression et peut être définie ainsi :
		 
		\begin{center}
		compression = $\frac{DL(G)}{DL(S)+DL(G|S)} $
		\end{center}
		
		\item  Dans le cas de l'utilisation des méthodes de clustering dans les deux méthodes \gls{ConDenSe} et \gls{vog}, nous obtenons une liste des structures les plus fréquentes. Pour chaque structure identifiée nous cherchons le motif qui la décrit le mieux en se basant sur un ensemble prédéfini de motifs (étoile, clique, noyau bipartie, semi clique, semi noyau bipartie, chaine). Afin de trouver le motif approximatif de la structure, nous utiliserons les formules proposées dans \citep{koutra2015summarizing} (voir section \ref{vog_desc}).
		
		\item Dans le cas de l'utilisation de la technique du MinHashing dans la méthode \gls{dsm}, nous utilisons le gain apporté par la compression des motifs comme métrique d'évaluation. Nous utilisons pour cela la même formule proposée dans \citep{buehrer2008scalable}. En effet, la qualité de compression d'un motif est calculée en fonction de sa fréquence dans la liste d'adjacence, et de sa taille qui est le nombre de liens qu'il contient (Formule \ref{eqcompperf}).
				%%% Formule
				\begin{equation}
				Compression(P)=(P.frequence-1)(P.taille-1)-1
				\label{eqcompperf}
				\end{equation}
				%Dans le cas de l'extraction de motifs à partir de la matrice d'adjacence aucune évaluation n'est nécessaire
		\item Dans le cas de la méthode \gls{gcupmt} qui se base sur l'extraction de motifs à partir de la matrice d'adjacence aucune évaluation n'est nécessaire car tout les motifs offrent le même gain d'espace mémoire.
		 
		
		 \end{enumerate}
		 
		   
		\subsubsection{Traitement des motifs :}
		
		Nous proposons pour traiter les motifs dans le moteur P-GraCE plusieurs alternatives, cela dépend de la méthode utilisée.
		
La première consiste à faire une agrégation des nœuds du meilleur motif. Les trois phases de compression seront donc répétées jusqu'à ce que la taille du graphe en sortie ne peut plus être optimisée. Elle est appliquée dans le cas de la méthode Subdue.

 La deuxième alternative est appliquée dans les deux méthodes \gls{ConDenSe} et \gls{vog}. Elle consiste à considérer que  la liste des sous-structures de l'étape d'évaluation représente le compressé du graphe de données : Nous effectuons une sélection à partir de l'ensemble des structures initiales pour obtenir un modèle (ensemble de structures) avec un MDL optimal. La sélection se fait à travers plusieurs heuristiques. Pour la méthode \gls{vog}, la sélection peut se faire à l'aide de trois algorithmes : \textit{Plain}, \textit{TopK} et \newacronym{gnf}{GNF}{Greedy'nForget} \gls{gnf}. \gls{ConDenSe} pour sa part utilise STEP comme heuristique de sélection . Nous présentons ci dessous chacune de ces heuristiques :
\begin{itemize}
\item \textit{Plain} : Cette algorithme sélectionne toutes les structures évaluées dans la phase précédente. 
\item \textit{TopK} : Cette méthode commence par ordonner les sous structures selon le gain de codage local apporté par chacune d'elles. Le gain de codage local est définit par L(g,$\emptyset$) - L(g,$\omega$) où  L(g,$\emptyset$) représente le cout de codage de g en tant qu'erreur et L(g,$\omega$) est le cout de codage de g avec la structure $\omega$ ($\omega$ est une structure du vocabulaire précédemment définit). Elle sélectionne ensuite les k meilleurs structures ayant un gain local élevé.
\item \gls{gnf} : Au lieu de prendre en compte toutes les combinaisons possibles des structures, l'heuristique 
\gls{gnf}
 considère les structures selon un ordre décroissant de leur gain d'encodage local. Elle parcourt structure par structure et inclut dans le modèle celle qui réduit le MDL. L'algorithme de \gls{gnf} est présenté dans ce qui suit (\ref{alg:GNF})   

\end{itemize}

\begin{algorithm}[H]
\label{alg:GNF}
	\caption{Geedy'nForget}
		\textbf{Entrée :}
		\begin{itemize}[label=$\bullet$]
			\item $\mathcal{C}$ : Listes des structures évaluées.
							
							
			\end{itemize}
	\textbf{Sortie :} ensemble des structures sélectionnées $\mathcal{M}$\\							\noindent\rule{\textwidth}{1pt}
								
	\begin{algorithmic} [1]
	 \STATE MDL-optimal = MDL(G,$\emptyset$)
\STATE Ordonner($\mathcal{C}$,"descendant") 
	\FOR{ $s \in \mathcal{C}$ }
	\STATE $\mathcal{M} = \mathcal{M} \cup {s}$ 
		\IF{ MDL(G,$\mathcal{M}$) <  MDL-optimal}
			\STATE MDL-optimal = MDL(G,$\mathcal{M}$)
		\ELSE 
			\STATE $\mathcal{M}$ = $\mathcal{M} \setminus {s}$  \COMMENT{Enlever la structure de l'ensemble}
		\ENDIF
	\ENDFOR   
	\end{algorithmic}
		\end{algorithm}

\begin{itemize}
\item STEP : Cette méthode parcourt de manière itérative toutes les structures évaluées précédemment dans un ordre quelconque et choisit la structure qui réduit le plus le MDL du modèle courant pour l'ajouter au modèle jusqu'à ce qu'aucune structure n'améliore le cout. Nous présentons l'algorithme détaillé ci-dessous :


\end{itemize}

\begin{algorithm}[H]
\label{alg:STEP}
	\caption{STEP}
		\textbf{Entrée :}
		\begin{itemize}[label=$\bullet$]
			\item $\mathcal{C}$ : Listes des structure évaluées.
							
							
			\end{itemize}
	\textbf{Sortie :} ensemble de structures sélectionnées $\mathcal{M}$\\							\noindent\rule{\textwidth}{1pt}
								
	\begin{algorithmic} [1]
	\STATE Best-Structure = -1
	 \STATE MDL-optimal = MDL(G,$\emptyset$)
	\WHILE{$\mathcal{C}$ != $\emptyset$}
	\FOR{ $s \in \mathcal{C}$ }
	\STATE $\mathcal{M} = \mathcal{M} \cup {s}$ 
		\IF{ MDL(G,$\mathcal{M}$) <  MDL-optimal}
			\STATE MDL-optimal = MDL(G,$\mathcal{M}$)
			\STATE Best-structure = s
		\ENDIF
		\STATE $\mathcal{M}$ = $\mathcal{M} \setminus {s}$  //Enlever la structure de l'ensemble
	\ENDFOR
	\IF{Best-Structure != -1}
	   \STATE $\mathcal{M} = \mathcal{M} \cup {Best-structure}$ 
	   \STATE Best-Structure = -1
	   \ELSE 
	   \STATE STOP
	  \ENDIF
		\STATE $\mathcal{C}$ = $\mathcal{C} \setminus {Best-Structure}$
	\ENDWHILE
	\end{algorithmic}
		\end{algorithm}


Pour la méthode \gls{dsm}, nous offrons  la possibilité d'utiliser le codage proposé dans \citep{liu2018reducing}. Il représente la liste de motifs de manière concise tout en permettant les requêtes d'extraction de voisinage. %Dans certaines méthodes une matrice d'erreur est conservée avec la liste des structures pour une compression sans perte.
Une fois les sous-structures identifiées dans la phase 2, chacune d'elles est représentée avec trois composantes: la première contenant les sommets ayant uniquement des arêtes sortantes, la deuxième contenant les sommets ayant des arêtes entrantes et sortantes et la troisième contenant les sommets ayant uniquement des arêtes entrantes. Pour pouvoir identifier les différentes composantes,  un vecteur binaire est associé à cette représentation marquant par un 1 le début de chacune des trois composantes (voir figure \ref{SDM}).\\

Pour la méthode \gls{gcupmt}, la matrice d'adjacence est remplacée par une séquence de bits, les motifs identifiés durant la phase d'extraction sont remplacés par leurs identifiants précédés par un 1 indiquant que les bits suivants appartiennent à un indicateur de motif. Dans le cas contraire, les valeurs des cases de la matrice serons stockées directement sous leur forme brute précédées par un 0.


Dans les méthodes \gls{vog}, \gls{ConDenSe} et \gls{dsm} une matrice d'erreur est conservée avec le résultat pour une compression sans perte.
		
		
		
	\section{Notre méthode: Dynamic Dense Subgraph Mining (DDSM)}
		\input{./ChapitresPFE/DDSM/ddsm.tex}
	
	\section{Conclusion}

Dans ce chapitre, nous avons expliqué la partie conceptuelle de nos deux moteurs: $k^2$-GraCE et P-GraCE, qui  représentent les deux classes qui font l'objet de notre recherche. Nous avons présenté leur différents modules et fonctionnalités tout en clarifiant leurs paramètres ainsi que leur principe de fonctionnement. Nous avons aussi proposé une nouvelle méthode de compression destinée pour les graphes dynamiques utilisant principalement la technique du Minhashing.

	Dans le chapitres suivant, nous présenterons les choix d'implémentation que nous avons effectués. Nous décrirons l'environnement de développement ainsi que l'architecture globale de notre projet. 
	
	
	

	

\input{./ChapitresPFE/implementation.tex}
	
	\input{./ChapitresPFE/tests.tex}




%\chapter{Conclusion Générale}
\newpage
\Huge{ 
			\textbf {Conclusion générale}} \\[0.5in]
			\addcontentsline{toc}{chapter}{\numberline{}Conclusion générale}
			\normalsize
De nos jours, les graphes sont omniprésents. Cependant, leur taille présente un obstacle presque insurmontable à la compréhension du caractère essentiel des données. D'où la nécessité de la compression qui permet de réduire la taille des graphes tout en gardant le caractère utile de l'information incluse dans ces derniers.\\

Dans notre travail, nous nous sommes focalisées  sur les méthodes de compression basées sur l'extraction de motifs et celles basées sur les arbres $k^2$-trees. Dans un premier temps, nous avons étudié les différentes méthodes et techniques s'inscrivant dans les deux classes ainsi que leurs différentes classifications existantes dans la littérature. Cette étude nous a initié au domaine de compression et nous a permis de mieux comprendre l'approche théorique de chaque classe. Suite à cela, nous avons proposé une nouvelle classification consistant en une rectification d'une ancienne classification proposée dans un Master précédent \citep{master2017}. Nous nous sommes basées pour cela sur le principe de fonctionnement et les fondements théoriques de ces méthodes. Nous avons conclu cette partie en établissant une étude comparative au sein d'une même classe et entre les deux classes en considérant différents critères: type de graphe en entrée, type de compression, .... \\

La deuxième partie de notre travail consiste en l'implémentation d'une méthode de chaque classe que nous avons proposée dans la première étape dans le but de les réunir dans une même plateforme et d'établir une comparaison plus objective entre ces techniques. De ce fait, nous avons proposé deux moteurs de compression de graphes (un moteur par classe). Le premier moteur $k^2$-GraCE exploite les propriétés de la matrice d'adjacence pour compresser le graphe. Il supporte trois types de graphe : graphes statiques orientés, graphes statiques non orientés et les graphes dynamiques. Nous l'avons doté d'une phase de pré-traitement qui permet d'exploiter davantage les caractéristiques des graphes. Le deuxième moteur P-GraCE quant à lui supporte trois types de graphes : graphes orientés statiques, graphes non orientés statiques et finalement les graphes étiquetés. Il englobe plusieurs méthodes de compression basées sur quatre approches différentes : la méthode Subdue basée sur le beam search, les deux méthodes \gls{vog} et \gls{ConDenSe} basées sur les techniques de clustering, la méthode \gls{dsm} basée sur le MinHashing et la méthode \gls{gcupmt} basée sur l'extraction de motifs à partir de la matrice d'adjacence. Nous avons aussi proposé une nouvelle méthode de compression s'intitulant \gls{ddsm} destinée pour les graphes dynamiques et permettant de fournir une compression interprétable du graphe initial. \\

La dernière étape de notre projet représente une étape d'évaluation des deux moteurs de compression ainsi que la méthode que nous avons proposée. Nous avons utilisé pour cela des graphes réels issus de domaines différents ainsi que trois métriques d'évaluation : le ratio de compression, le nombre de bits par nœud et le temps d'exécution. Dans le cas du moteur $k^2$-GraCE, nous avons montré que l'utilisation de la matrice d'adjacence dégrade les performances en terme de temps d'exécution et que l'utilisation de la liste d'adjacence ou la structure de la bibliothèque \gls{snap} donne des résultats meilleurs. Pour le module de pré-traitement de ce moteur, nous avons constaté que  l'utilisation d'algorithme de ré-ordonnancement  ne donne une amélioration que dans le cas des graphes qui ne sont pas issus du domaine du web. Nous avons aussi obtenu une amélioration d'un facteur de 2 du ratio de compression lorsque la partie supérieure uniquement de la matrice est considérée. Le meilleur ratio obtenu pour ce moteur est de 5474 dans le cas du graphe Retilia--toroise-network-bsv qui est un graphe dynamique.
Pour le deuxième moteur P-GracE, les tests ont montré que, dans le cas de la méthode \gls{gcupmt} qui est basée sur les propriétés de la matrice d'adjacence, les motifs de la classe (01) ou de la classe (03) (i.e les motifs de ayant la forme suivante: 10...010...0) sont plus intéressants. Nous avons aussi constaté que l'approche basée sur les méthodes de clustering produit une meilleur compression avec la méthode \gls{ConDenSe} qui utilise les trois méthodes de clustering ensemble pour l'extraction de motifs et la méthode \textit{Step} comme méthode de sélection. Concernant la méthode que nous avons proposée, nous avons obtenu un ratio de compression qui se stabilise à partir de 50 permutations avec un temps de compression compétitif.  
La comparaison entre les deux moteurs a montré que le moteur $k^2$-GraCE donne des résultats nettement meilleurs que le moteur P-GraCE en terme de taux de compression et de temps d'exécution. Cependant, le moteur P-GraCE produit une compression qui facilite l'analyse et la compréhension du graphe initial à travers ses sous-structures les plus importantes ayant généralement une interprétation selon le domaine d'application.  \\
	
	
Comme perspective à ce travail, nous aimerions bien tester nos deux moteurs avec des graphes encore plus larges pour pouvoir les évaluer davantage. Nous voudrons aussi tester notre méthode contre les méthodes existantes dans la littérature, notamment TimeCrunch \citep{shah2015timecrunch}, sur les mêmes graphes afin de mieux comparer et situer notre contribution dans la littérature.






\pagestyle{plain}
\newpage

\begin{appendix}


\chapter{Extraction de voisins dans un arbre $k^2$-tree}
    \label{k2_annexe}
La compression par les arbres $k^2$-trees a connu un large succès dans la communauté scientifique. L'une des causes les plus importantes qui ont favorisé cela est qu'elle permet d'extraire le voisinage des nœuds sans reconstitution du graphe initiale. Cette partie se veut une explication des deux algorithmes d'extraction de voisins directes et inverses. 

Comme nous l'avons déjà expliqué dans la section \ref{k2} de la partie conception   du moteur $k^2$-GraCE, les arbres $k^2$-tree sont représentés en mémoire à l'aide de deux chaines binaires, T et L, qui regroupe le contenu de l'arbre de haut vers le bas et de la gauche vers la droite. Nous fournissons ci-après les algorithmes d'extraction de voisinage \citep{brisaboa2009k}.



\begin{multicols}{2}

\begin{algorithm}[H]
					\label{alg:Direct}
					\caption{Direct}
					\textbf{Entrée :}
						\begin{itemize}[label=$\bullet$]
							\item n : la taille de la sous-matrice
							\item p : l'indice de la ligne 
							\item q : l'indice de la colonne
							\item x : l'indice dans l'arbre
						\end{itemize}
					\textbf{Sortie :} affichage des voisins Directes\\							\noindent\rule{\textwidth}{1pt}
						
						
				\begin{algorithmic} [1]
					\IF {x $\geqslant$ |T|}
						\IF { L[x-|T|] =1 }
							\STATE afficher q
						\ENDIF
					\ELSE
						\IF { x = -1 ou T[x]=1  }
							\STATE y = rank(T,x)*$k^2$ + p/(n/k)
							\FOR{ j =0 ... k-1}
								\STATE Direct(n/k,p mod(n/k),q+ j*(n/k),y+j)
							\ENDFOR
						\ENDIF
					\ENDIF 
					
					
				\end{algorithmic}
			\end{algorithm}


 
\columnbreak
 
\begin{algorithm}[H]
					\label{alg:Inverse}
					\caption{Inverse}
					\textbf{Entrée :}
						\begin{itemize}[label=$\bullet$]
							\item n : la taille de la sous-matrice
							\item q : l'indice de la colonne
							\item p : l'indice de la ligne 
							\item x : l'indice dans l'arbre
						\end{itemize}
					\textbf{Sortie :} affichage des voisins Inverses\\							\noindent\rule{\textwidth}{1pt}
						
						
				\begin{algorithmic} [1]
					\IF {x $\geqslant$ |T|}
						\IF { L[x-|T|] =1 }
							\STATE afficher p
						\ENDIF
					\ELSE
						\IF { x = -1 ou T[x]=1  }
							\STATE y = rank(T,x)*$k^2$ + q/(n/k)
							\FOR{ j =0 ... k-1}
								\STATE Inverse(n/k,q mod(n/k),p+ j*(n/k),y+j*k)
							\ENDFOR
						\ENDIF
					\ENDIF 
					
					
				\end{algorithmic}
			\end{algorithm}
			
\end{multicols}

\chapter{Description des graphes de test}
 \label{tableau des graphes de test}
 \begin{table}[H]
 \begin{tabular}{|C{5cm}|C{4.5cm}|C{4.5cm}|}
		\hline
		\multirow{2}{*}{Graphe de test} & \multicolumn{2}{c|}{Caractéristiques}  \\ \cline{2-3}
				&  Nombre de nœuds & Nombre de liens  \\ \hline	 \hline	
 
eu-2005  & 862 milles de nœuds & 19M de liens \\ \hline
Cond-mat  & 36 milles de nœuds & 171 milles de liens \\ \hline
CommNet & \multicolumn{2}{c|}{taille : 225.9MB} \\ \hline
SalesDay & 1 milles de nœuds & \\ \hline
Movielens10M  & 10 milles de nœuds & 10M de liens \\ \hline
ASOregon &  13 milles nœuds & 37 milles liens \\ \hline
 Enron  &  80 milles nœuds& 288 milles liens \\ \hline
 uk-2002   & 18 milles nœuds & 298 milles liens \\ \hline
 graphe test de GCUPMT &  8 192 milles nœuds & \\ \hline
 Composante chimique &  21 étiquettes & 422 transactions \\ \hline
 NotreDame  &  325 milles de nœuds & 1M de liens \\ \hline

\end{tabular}
									\caption{Graphes de test}									\label{comgen}

 								\end{table}



\begin{itemize}

\item Les graphes eu-2005, Enron et uk-2002 sont disponibles sur \url{http://law.di.unimi.it/datasets.php}

\item Le graphe NotreDame est disponible sur \url{http://vlado.fmf.uni-lj.si/pub/networks/data/}

\item Le graphe Movielens10M est disponible sur \url{https://grouplens.org/datasets/movielens/10m/}

\item Le graphe Cond-mat  est disponible sur (M.E.J. Newman, The structure of scientific collaboration networks, Proceedings of the National Academy of Sciences USA 98 (2) (2001) 404–409)
\end{itemize}






\newpage


\chapter{Algorithmes des méthodes de clustering}

\label{SlashBurn}

\begin{algorithm}[H]
					\label{alg:SlashBurn}
					\caption{SlashBurn}
					\textbf{Entrée :}
						\begin{itemize}[label=$\bullet$]
							\item G(V,E) : Graphe non orienté 
							\item n : nombre de nœuds dans le graphe 
							
						\end{itemize}
					\textbf{Sortie :} structures : ensemble de structures\\							\noindent\rule{\textwidth}{1pt}
						
						
				\begin{algorithmic} [1]
				
				 \STATE D = [] //tableau de degré
				 \STATE composantesConx = \{\} //Ensemble de sous graphes connexes
				 \STATE GCC = G			 
				 \WHILE{tailleGCC >2} 	 
				 \FOR{ $v_i \in V$}
				 \STATE D[i] = \textbf{Degré}($v_i$)
				 \ENDFOR
				 
					\STATE hub = \{ $v_i$ | i=max(D[i])\}
					\STATE composantesConx = \textbf{composantes-connexe}(GCC)
					\STATE Etoile = GCC($hub \cup \textbf{vosins}(hub)$)
					\STATE GCC = \{ $g \in composantesConx$ | g ayant le degré maximal \}
					\STATE structures = $structures \cup Etoile \cup \{composantesConx/GCC\}$
					
					\ENDWHILE
				
				
				\end{algorithmic}
			\end{algorithm}

\newpage

\label{KCBC}


\begin{algorithm}[H]
					\label{alg:KCBC}
					\caption{KCBC}
					\textbf{Entrée :}
						\begin{itemize}[label=$\bullet$]
							\item G : Graphe non orienté
							\item n : nombre de nœuds dans le graphe 
							
						\end{itemize}
					\textbf{Sortie :} ensemble de structures\\							\noindent\rule{\textwidth}{1pt}
						
						
				\begin{algorithmic} [1]
				\STATE Degré = 	\lbrack \rbrack
				\STATE F = G
				\STATE stop = VRAI
				\STATE structure = \{\}
				\STATE //étape 1 : Calculer le degré de chaque nœud
					\FOR{ i =0 ... n-1}
					  \STATE Degré \lbrack i \rbrack = $\textbf{Deg}_G$(i)
					  \ENDFOR
					  \STATE $k_{max}$ = k
						\WHILE { $k_{max}$ > 1 and and stop = VRAI }
						\STATE //étape 2 : Décomposition du graphe avec $k_{max}$
						\STATE F = G
						\FOR{ x =0 ... n-1}
							\IF { $\textbf{DEG}_F$(x) < $k_{max}$}
							\STATE $\textbf{Supprimer}_F$(x) 
							\ENDIF
							
						\ENDFOR
						
						\IF { F = {} }
							\STATE stop = FAUX
						
					\ELSE
						\STATE $k_{max}$ = $k_{max}$ - 1
					\ENDIF
					\ENDWHILE 
					
					
					\STATE //étape 3 : Identification des structures 
					
					\STATE structure = structure $\cup$ \{ composants connexes $ \in $ F \}
					 
					 \STATE //étape 4 : Suppression des arêtes entre structures
					 \FOR{ $struct_i$, $struct_j$ $\in$ structure } 
					 \STATE $\textbf{supprimerArête}_F$($struct_i \cap struct_j$)   
					 \ENDFOR
				\end{algorithmic}
			\end{algorithm}

\end{appendix}
\newpage




\bibliographystyle{apalike}
\bibliography{Bibliographie}

\end{document}

%\renewcommand{\thefigure}{\arabic{figure}}
%\setcounter{figure}{0}
%\begin{figure}[H]
%	\centering
%	\includegraphics[scale=1]{ressources/image/LAAS-2016.jpg}
%	\label{fig:figure1}
%	\caption{This is a teste of figure}
	
%\end{figure}








